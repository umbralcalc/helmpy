{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive notebook of `helmpy` examples\n",
    "\n",
    "In this notebook we will run through all of the features in `helmpy` as well as providing insights into its construction along the way. Throughout we shall be running the algorithm only once to generate our plots, however for best results it is recommended to rerun `helmpy` a few more times (fewer than $10$ iterations) and to combine the output. Because a number of realisations may be run at once (e.g., $250$), this can lead to very good statistics in the output (overall $10 \\times 250$ realisations) with high efficiency.\n",
    "\n",
    "First we must tell the system where the `helmpy` directory is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_to_helmpy = '/Users/Rob/work/helmpy' # Give your path to helmpy here\n",
    "sys.path.append(path_to_helmpy + '/source/') \n",
    "from helmpy import helmpy\n",
    "\n",
    "# These modules are not necessary to run helmpy alone but will be useful for our demonstrations\n",
    "\n",
    "# LEAVE THESE IMPORTS COMMENTED AS THEY ARE FOR PRODUCING LaTeX-STYLE FIGURES ONLY\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "#mpl.rc('font',family='CMU Serif')\n",
    "#mpl.rcParams['xtick.labelsize'] = 15\n",
    "#mpl.rcParams['ytick.labelsize'] = 15\n",
    "#mpl.rcParams['axes.labelsize'] = 20\n",
    "#from matplotlib import rc\n",
    "#rc('text',usetex=True)\n",
    "#rc('text.latex',preamble=r'\\usepackage{mathrsfs}')\n",
    "#rc('text.latex',preamble=r'\\usepackage{sansmath}')\n",
    "# LEAVE THESE IMPORTS COMMENTED AS THEY ARE FOR PRODUCING LaTeX-STYLE FIGURES ONLY\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Soil-transmitted helminths (STH)\n",
    "\n",
    "## 1.1 Running basic simulations in three steps\n",
    "\n",
    "### Step 1\n",
    "\n",
    "Initialise the `helmpy` class by specifying a disease type and working directory..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = helmpy(\n",
    "            'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "            path_to_helmpy,                     # Set the path to the working directory\n",
    "            suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "            )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Set the parameters and initial conditions for the simulation. List sizes are variable depending on the number of groupings one wishes to apply. Hence age, gender and all other stratifications within a cluster may be programmed in straightforwardly and each grouping may be identified within a given cluster by a spatial index. The available basic options to vary are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hp.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hp.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hp.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "#hp.parameter_dictionary['R0'] = [3.5,3.0]       # Basic reproduction number within grouping\n",
    "hp.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hp.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hp.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hp.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hp.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "#hp.initial_conditions['M'] = [2.9,3.1]          # Initial mean total worm burden within grouping\n",
    "hp.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping\n",
    "#hp.initial_conditions['FOI'] = [1.25,1.5]       # Initial force of infection (per year) within grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are running two non-interacting clusters each with a single grouping of people which both contain different numbers of people, different initial conditions, different parasite clumping (controlled through $k$) and different overall values of parasite uptake: here combined into a parameter we call `R0` - note that these are different to the true $R_0$ value in the cluster which can be computed from the weighted sum of these sub-`R0` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Run the simulation by setting the key numerical parameters. For comparison we will also run the mean field and mean field stochastic codes (which are much faster) alongside the full simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'default_example'           # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time  \n",
    "hp.run_full_stoch(         \n",
    "                  runtime,          \n",
    "                  realisations,  \n",
    "                  do_nothing_timescale,\n",
    "                  output_filename,  \n",
    "                  timesteps_snapshot=output_timesteps\n",
    "                  )\n",
    "\n",
    "hp.run_meanfield_stoch(         \n",
    "                       runtime, \n",
    "                       realisations,\n",
    "                       do_nothing_timescale,                \n",
    "                       'meanfield_stoch_' + output_filename,\n",
    "                       timesteps_snapshot=output_timesteps\n",
    "                       )\n",
    "\n",
    "hp.run_meanfield(         \n",
    "                 runtime,  \n",
    "                 do_nothing_timescale,                \n",
    "                 'meanfield_' + output_filename       \n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run all three models, let us now read in the data and compare the ensemble mean and variance of the mean worm burden realisations in each cluster.\n",
    "\n",
    "First we compare the predictions of the mean field model to those of the full simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_meanfield_output_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hp.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hp.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hp.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hp.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hp.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hp.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hp.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hp.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hp.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hp.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# Mean field of ensemble in cluster 1\n",
    "plt.plot(example_meanfield_output_data.T[0],example_meanfield_output_data.T[1],color='r',alpha=0.4) \n",
    "\n",
    "# Mean field of ensemble in cluster 2\n",
    "plt.plot(example_meanfield_output_data.T[0],example_meanfield_output_data.T[2],color='b',alpha=0.4) \n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([2.5,7.5])\n",
    "axes.set_ylabel(r'$M(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12)\n",
    "plt.savefig(path_to_helmpy + '/plots/Mean_meanfield_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_meanfield_output_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_' + output_filename + '.txt')\n",
    "\n",
    "# Variance of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[3],color='r',\\\n",
    "         label=r'$R_0 =' + str(hp.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hp.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hp.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hp.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hp.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Variance of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[4],color='b',\\\n",
    "         label=r'$R_0 =' + str(hp.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hp.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hp.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hp.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hp.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "\n",
    "# Variance from mean field of ensemble in cluster 1\n",
    "plt.plot(example_meanfield_output_data.T[0],example_meanfield_output_data.T[3],color='r',alpha=0.4)\n",
    "\n",
    "# Variance from mean field of ensemble in cluster 2\n",
    "plt.plot(example_meanfield_output_data.T[0],example_meanfield_output_data.T[4],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,2.5])\n",
    "axes.set_ylabel(r'$V(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12)\n",
    "plt.savefig(path_to_helmpy + '/plots/Var_meanfield_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we compare the predictions of a fast stochastic model built from the mean field code to those of the full simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_meanfield_stoch_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_stoch_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hp.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hp.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hp.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hp.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hp.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hp.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hp.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hp.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hp.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hp.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[5],color='r')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[6],color='b')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[8],color='b')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 1\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[1],color='r',alpha=0.4)\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 2\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[2],color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 1\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[5],color='r',alpha=0.4)\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[7],color='r',alpha=0.4)\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 2\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[8],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,9.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12, loc = 9)\n",
    "plt.savefig(path_to_helmpy + '/plots/meanfield_stoch_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us also have a look at some snapshots in time of the mean worm burden distribution from the full simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_values = [1000,2000,3000,9000]\n",
    "alphlist = [0.2,0.4,0.6,1.0]\n",
    "\n",
    "for ti in range(0,len(time_values)):\n",
    "    wb_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + \\\n",
    "                         '_snapshot_timestep_' + str(time_values[ti]) + '_cluster_1.txt')\n",
    "    bo = np.histogram((np.sum(wb_data,axis=1)/len(wb_data.T)).astype(float),bins='fd',density=True)\n",
    "    box = 0.5*(bo[1][:len(bo[0])]+bo[1][1:len(bo[0])+1])\n",
    "    boy = bo[0]\n",
    "    plt.plot(box[boy!=0.0],(boy/max(boy))[boy!=0.0],color='r',alpha=alphlist[ti])\n",
    "    \n",
    "for ti in range(0,len(time_values)):\n",
    "    wb_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + \\\n",
    "                         '_snapshot_timestep_' + str(time_values[ti]) + '_cluster_2.txt')\n",
    "    bo = np.histogram((np.sum(wb_data,axis=1)/len(wb_data.T)).astype(float),bins='fd',density=True)\n",
    "    box = 0.5*(bo[1][:len(bo[0])]+bo[1][1:len(bo[0])+1])\n",
    "    boy = bo[0]\n",
    "    plt.plot(box[boy!=0.0],(boy/max(boy))[boy!=0.0],color='b',alpha=alphlist[ti])\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0.0,8.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the equivalent from the mean field stochastic code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_values = [1000,2000,3000,9000]\n",
    "alphlist = [0.2,0.4,0.6,1.0]\n",
    "\n",
    "for ti in range(0,len(time_values)):\n",
    "    mwb_data = np.loadtxt(path_to_helmpy + '/data/'  + 'meanfield_stoch_' + output_filename + \\\n",
    "                          '_snapshot_timestep_' + str(time_values[ti]) + '_cluster_1.txt')\n",
    "    bo = np.histogram(mwb_data.astype(float),bins='fd',density=True)\n",
    "    box = 0.5*(bo[1][:len(bo[0])]+bo[1][1:len(bo[0])+1])\n",
    "    boy = bo[0]\n",
    "    plt.plot(box[boy!=0.0],(boy/max(boy))[boy!=0.0],color='r',alpha=alphlist[ti])\n",
    "    \n",
    "for ti in range(0,len(time_values)):\n",
    "    mwb_data = np.loadtxt(path_to_helmpy + '/data/'  + 'meanfield_stoch_' + output_filename + \\\n",
    "                          '_snapshot_timestep_' + str(time_values[ti]) + '_cluster_2.txt')\n",
    "    bo = np.histogram(mwb_data.astype(float),bins='fd',density=True)\n",
    "    box = 0.5*(bo[1][:len(bo[0])]+bo[1][1:len(bo[0])+1])\n",
    "    boy = bo[0]\n",
    "    plt.plot(box[boy!=0.0],(boy/max(boy))[boy!=0.0],color='b',alpha=alphlist[ti])\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0.0,8.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Adding inter-cluster migration\n",
    "\n",
    "To begin with, let us create a new instance of `helmpy` with the same parameters and initial conditions set for comparison in order to continue working distinctly from the previous section..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpmig = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "              ) \n",
    "\n",
    "hpmig.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hpmig.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hpmig.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hpmig.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hpmig.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hpmig.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hpmig.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hpmig.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hpmig.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hpmig.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run the basic simulations above for two separate clusters, let us now introduce an inter-cluster migration effect by specifying non-zero migratory rate matrices with the following definitions: Components $(r_+)_{ij}$ and $(r_-)_{ij}$ are the migration rates (per year) of individuals in to cluster $i$ from cluster $j$ and out of cluster $i$ from cluster $j$, respectively. Hence, the matrices for two clusters are\n",
    "\n",
    "$${\\bf r}_+ = \\begin{bmatrix} (r_+)_{11} & (r_+)_{12} \\\\ (r_+)_{21} & (r_+)_{22}\\end{bmatrix}\\,,\\qquad {\\bf r}_- = \\begin{bmatrix} (r_-)_{11} & (r_-)_{12} \\\\ (r_-)_{21} & (r_-)_{22}\\end{bmatrix}\\,,$$\n",
    "\n",
    "and one may deduce that $(r_+)_{ij}=(r_-)_{ji}$. Let us now set these matrices in the parameters of our `helmpy` instance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpmig.parameter_dictionary['r+'] = [[0.0,0.0],[52.0,0.0]]  # Migration matrix - the migration rate in (per year)\n",
    "hpmig.parameter_dictionary['r-'] = [[0.0,52.0],[0.0,0.0]]  # Migration matrix - the migration rate out (per year)\n",
    "hpmig.parameter_dictionary['Nm'] = [1]                     # Number of migrants per event (global parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the migrations have been set, we may simply rerun the code as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'default_example'           # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time  \n",
    "\n",
    "hpmig.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'mig_' + output_filename,  \n",
    "                    timesteps_snapshot=output_timesteps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_output_data_mig = np.loadtxt(path_to_helmpy + '/data/' + 'mig_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1 with migration\n",
    "plt.plot(example_output_data_mig.T[0],example_output_data_mig.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hpmig.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hpmig.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hpmig.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hpmig.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hpmig.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig.T[0],example_output_data_mig.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hpmig.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hpmig.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hpmig.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hpmig.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hpmig.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1 with migration\n",
    "plt.plot(example_output_data_mig.T[0],example_output_data_mig.T[5],color='r')\n",
    "plt.plot(example_output_data_mig.T[0],example_output_data_mig.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig.T[0],example_output_data_mig.T[6],color='b')\n",
    "plt.plot(example_output_data_mig.T[0],example_output_data_mig.T[8],color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 1 \n",
    "plt.plot(example_output_data.T[0],example_output_data.T[1],color='r',alpha=0.4)\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[5],color='r',alpha=0.4)\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[7],color='r',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[8],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,8.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12, loc = 9)\n",
    "plt.text(50.0,0.5,r'$(r_+,r_-)=(' + \\\n",
    "         str(np.round(hpmig.parameter_dictionary['r+'][0][1]/ \\\n",
    "                      hpmig.parameter_dictionary['mu2'][0],decimals=1)) + '\\mu_2,' + \\\n",
    "         str(np.round(hpmig.parameter_dictionary['r-'][0][1]/ \\\n",
    "                      hpmig.parameter_dictionary['mu2'][0],decimals=1)) + '\\mu_2)$', \\\n",
    "          color='r',fontsize=15)\n",
    "plt.savefig(path_to_helmpy + '/plots/mig_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let once again have a look at some snapshots in time of the mean worm burden distribution from the full simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_values = [1000,2000,3000,9000]\n",
    "alphlist = [0.2,0.4,0.6,1.0]\n",
    "\n",
    "for ti in range(0,len(time_values)):\n",
    "    wb_data = np.loadtxt(path_to_helmpy + '/data/' + 'mig_' + output_filename + \\\n",
    "                         '_snapshot_timestep_' + str(time_values[ti]) + '_cluster_1.txt')\n",
    "    bo = np.histogram((np.sum(wb_data,axis=1)/len(wb_data.T)).astype(float),bins='fd',density=True)\n",
    "    box = 0.5*(bo[1][:len(bo[0])]+bo[1][1:len(bo[0])+1])\n",
    "    boy = bo[0]\n",
    "    plt.plot(box[boy!=0.0],(boy/max(boy))[boy!=0.0],color='r',alpha=alphlist[ti])\n",
    "    \n",
    "for ti in range(0,len(time_values)):\n",
    "    wb_data = np.loadtxt(path_to_helmpy + '/data/' + 'mig_' + output_filename + \\\n",
    "                         '_snapshot_timestep_' + str(time_values[ti]) + '_cluster_2.txt')\n",
    "    bo = np.histogram((np.sum(wb_data,axis=1)/len(wb_data.T)).astype(float),bins='fd',density=True)\n",
    "    box = 0.5*(bo[1][:len(bo[0])]+bo[1][1:len(bo[0])+1])\n",
    "    boy = bo[0]\n",
    "    plt.plot(box[boy!=0.0],(boy/max(boy))[boy!=0.0],color='b',alpha=alphlist[ti])\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0.0,8.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Adding treatment rounds\n",
    "\n",
    "The `helmpy` class models rounds of mass drug administration (MDA) through Bernoulli trials with a given probability of reducing an individual's worm burden to 0. This is effectively a 'random compliance' model. Let us use this feature to examine the influence of migration on the efficacy of treatment using the system setup from before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Boolean to see the effect of migration for simplicity...\n",
    "with_migration = False\n",
    "\n",
    "hptrt = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "              ) \n",
    "\n",
    "hptrt.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hptrt.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hptrt.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hptrt.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hptrt.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hptrt.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hptrt.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hptrt.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hptrt.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hptrt.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping\n",
    "\n",
    "if with_migration == True:\n",
    "    hptrt.parameter_dictionary['r+'] = [[0.0,0.0],[52.0,0.0]] # Migration matrix - the migration rate in (per year)\n",
    "    hptrt.parameter_dictionary['r-'] = [[0.0,52.0],[0.0,0.0]] # Migration matrix - the migration rate out (per year)\n",
    "    hptrt.parameter_dictionary['Nm'] = [10]                   # Number of migrants per event (global parameter) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having initialised a new instance, let us define 3 rounds of MDA with 60% coverage at years 15, 16 and 17 to see the effect this has on the disease..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_coverages = [[0.6,0.6,0.6],         # A list of lists matching the chosen groupings which gives \n",
    "                       [0.6,0.6,0.6]]         # the effective coverage fraction in each\n",
    "\n",
    "treatment_times = [15.0,16.0,17.0]            # A list of treatment times for all clusters\n",
    "\n",
    "hptrt.add_treatment_prog(\n",
    "                        treatment_times,         \n",
    "                        treatment_coverages=treatment_coverages,\n",
    "                        drug_efficacy=1.0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the simulation which will output both the mean worm burden dynamics (as before) and the final prevalence realisations at the last round of treatment and at the absolute end of the runs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'default_example'           # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time\n",
    "\n",
    "if with_migration == False:   \n",
    "    hptrt.run_full_stoch(         \n",
    "                        runtime,          \n",
    "                        realisations,  \n",
    "                        do_nothing_timescale,\n",
    "                        'trt_' + output_filename,  \n",
    "                        timesteps_snapshot=output_timesteps\n",
    "                        )\n",
    "    \n",
    "if with_migration == True:   \n",
    "    hptrt.run_full_stoch(         \n",
    "                        runtime,          \n",
    "                        realisations,  \n",
    "                        do_nothing_timescale,\n",
    "                        'mig_trt_' + output_filename,  \n",
    "                        timesteps_snapshot=output_timesteps\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data_mig_trt = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + '.txt')\n",
    "example_output_data_trt = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hptrt.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hptrt.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hptrt.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hptrt.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hptrt.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hptrt.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hptrt.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hptrt.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hptrt.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hptrt.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[5],color='r')\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[6],color='b')\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[8],color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 1 \n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[1],color='r',alpha=0.4)\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[2],color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[5],color='r',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[7],color='r',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[8],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,8.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12, loc = 9)\n",
    "#plt.text(50.0,1.0,r'$(r_+,r_-)=(' + str(hptrt.parameter_dictionary['r+'][0][1]) + ',' + \\\n",
    "#                                    str(hptrt.parameter_dictionary['r-'][0][1]) + ')$',color='r',fontsize=15)\n",
    "plt.savefig(path_to_helmpy + '/plots/treat_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b3)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b4)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Adding individual non-compliance to the treatment rounds\n",
    "\n",
    "The `helmpy` class also contains models for systematic individual non-compliance to the MDA programme in the form of the conditional probabilities of: individuals in the $j$-th grouping being treated in the $n$-th round given treatment in the $(n-1)$-th round $\\alpha^j_{n,n-1}$ and being treated in the $n$-th round given non-treatment in the $(n-1)$-th round $\\beta^j_{n,n-1}$ in a Markov model such that the probability of an individual in the $j$-th grouping is treated in the $n$-th round may be written as\n",
    "\n",
    "$$p_{j,n} = \\alpha^j_{n,n-1} p_{j,n-1} + \\beta^j_{n,n-1} [1 - p_{j,n-1}]\\,.$$\n",
    "\n",
    "To demonstrate how this model impacts the MDA scenario we have already been working with, let us once again re-initialise `helmpy`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpcom = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "              ) \n",
    "\n",
    "hpcom.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hpcom.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hpcom.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hpcom.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hpcom.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hpcom.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hpcom.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hpcom.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hpcom.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hpcom.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having initialised another new instance, let us define the same 3 rounds of MDA with the same effective 60% coverage at years 15, 16 and 17 but with compliance parameters which indicate systematic individual non-compliance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_alpha_betas = [[0.6,0.4,0.97,0.05,0.97,0.05],     # A list of lists matching the chosen groupings which gives \n",
    "                    [0.6,0.4,0.97,0.05,0.97,0.05]]     # the alpha and beta parameters in the order of \n",
    "                                                       # alpha_1, beta_1, alpha_2,... in each, where the \n",
    "                                                       # first round alpha is an initial coverage fraction\n",
    "    \n",
    "treatment_times = [15.0,16.0,17.0]                     # A list of treatment times for all clusters\n",
    "\n",
    "hpcom.add_treatment_prog(\n",
    "                        treatment_times,         \n",
    "                        compliance_params=comp_alpha_betas,\n",
    "                        drug_efficacy=1.0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to run the code and plot the same outputs at the end of the runs as before for comparison..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'default_example'           # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time\n",
    "\n",
    "hpcom.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'com_' + output_filename,  \n",
    "                    timesteps_snapshot=output_timesteps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data_com = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + '.txt')\n",
    "example_output_data_trt = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hpcom.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hpcom.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hpcom.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hpcom.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hpcom.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hpcom.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hpcom.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hpcom.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hpcom.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hpcom.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[5],color='r')\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[6],color='b')\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[8],color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 1 \n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[1],color='r',alpha=0.4)\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[2],color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[5],color='r',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[7],color='r',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[8],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,8.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12, loc = 9)\n",
    "#plt.text(50.0,1.0,r'$(r_+,r_-)=(' + str(hptrt.parameter_dictionary['r+'][0][1]) + ',' + \\\n",
    "#                                    str(hptrt.parameter_dictionary['r-'][0][1]) + ')$',color='r',fontsize=15)\n",
    "plt.savefig(path_to_helmpy + '/plots/noncomptreat_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b3)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b3)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Running large numbers of people and clusters\n",
    "\n",
    "In order to run `helmpy` with a large number of people and clusters, it is advised to reduce the number of realisations to 1 as the internal vectorisation which optimises the code cannot handle matrices that are too large. The example below tests the runtime of helmpy with 500 people each in 40 clusters including migration and treatment rounds and emphasises the simplicity of using the `helmpy` class to instanciate a run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                              \n",
    "realisations = 1                              \n",
    "do_nothing_timescale = 0.01                                                 \n",
    "    \n",
    "output_filename = 'tests'                  \n",
    "\n",
    "treatment_coverages = [[0.6,0.6,0.6] for j in range(0,40)]                          \n",
    "treatment_times = [15.0,16.0,17.0]     \n",
    "\n",
    "hptest = helmpy('STH',path_to_helmpy,suppress_terminal_output=True) \n",
    "hptest.parameter_dictionary['Np'] = [500 for j in range(0,40)]         \n",
    "hptest.parameter_dictionary['spi'] = [j for j in range(0,40)]         \n",
    "hptest.parameter_dictionary['r+'] = [[10.0*(i!=j) for i in range(0,40)] for j in range(0,40)] \n",
    "hptest.parameter_dictionary['r-'] = [[10.0*(i!=j) for i in range(0,40)] for j in range(0,40)]\n",
    "hptest.add_treatment_prog(treatment_times,treatment_coverages=treatment_coverages,drug_efficacy=1.0) \n",
    "\n",
    "start_time = time.time()\n",
    "hptest.run_full_stoch(runtime,realisations,do_nothing_timescale,output_filename)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Runtime: ' + str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which appears to be around the 22 minute mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
