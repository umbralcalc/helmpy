{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive notebook for using `helmpy` mean field models for parameter inference from data\n",
    "\n",
    "The mean field or 'deterministic' models which can be run with the `helmpy.run_meanfield` method can be used to provide an efficient way to perform approximate posterior parameter inference with respect to some dataset(s), but before we illustrate how to do this, it will be informative to describe the theoretical background necessary to perform this inference. Note that this notebook will assume prior knowledge with the interface of `helmpy`, so to make sure that this is familiar it is suggested that one reads through helmpy_examples.ipynb before continuing here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical background\n",
    "\n",
    "Here we outline the basic theoretical background for performing Bayesian parameter inference using mean field helminth models under the assumption that the system close to a state of endemic equilibrium. For helminth transmission parameter inference far out of equilibrium, or close to the unstable breakpoint in the transmission phase plane (for reference: [https://www.sciencedirect.com/science/article/pii/S002251931930445X ]), it is not recommended that mean field models are used for many of the reasons outlined in [https://www.medrxiv.org/content/10.1101/2019.12.17.19013490v1 ] - in such instances, the stochastic inference method is recommended, though it is more computationally expensive. Bear in mind, also, that inference with the mean field model will typically underestimate the variance of the posterior over parameters in comparison to inference with the stochastic model and so it should be used when population sizes are larger so that this additional variance is minimised.\n",
    "\n",
    "The formalism we will outline here assumes that the diagnostic data are either Kato-Katz counts (for _Ascaris lumbricoides, Trichuris trichiura, Schistosoma mansoni_ and hookworm diagnostic testing) or urine filtration counts (for _Schistosoma haematobium_ diagnostic testing). As ever in any canonical Bayesian problem, specification of the likelihood function ${\\cal L}$ is not the end of the story. To infer a full joint posterior distribution ${\\cal P}$ given a dataset ${\\cal D}$ over the collection of transmission and diagnostic parameters $\\{ R_0(a), M (a,t_0),k,z,\\lambda_{\\rm d},k_{\\rm d} \\}$, Bayes' rule here reads \n",
    "\n",
    "$${\\cal P}[ R_0(a), M (a,t_0),k,z,\\lambda_{\\rm d},k_{\\rm d}  \\vert {\\cal D}] = \\frac{1}{{\\cal E}} \\pi [R_0(a)]\\, \\pi [M (a,t_0)] \\, \\pi (k) \\, \\pi (z) \\, \\pi (\\lambda_{\\rm d})\\, \\pi (k_{\\rm d}) \\,{\\cal L}[{\\cal D}\\vert R_0(a), M (a,t_0),k,z,\\lambda_{\\rm d},k_{\\rm d} ] \\,,$$\n",
    "\n",
    "where ${\\cal E}$ is a normalisation constant and $\\pi [R_0(a)]$, $\\pi [M (a,t_0)]$, $\\pi (k)$, $\\pi (z)$, $\\pi (\\lambda_{\\rm d})$ and $\\pi (k_{\\rm d})$ are the prior distributions over $R_0(a)$, $M (a,t_0)$ $k$, $z$, $\\lambda_{\\rm d}$ and $k_{\\rm d}$ which are the age-dependent contributions to the basic reproduction number, the age-dependent initial condition to the mean total worm burden per individual (which, when combined with $R_0(a)$ and the other parameters, specify the dynamics $M(a,t)$), worm aggregation, density dependent fecundity factor, the number of diagnostically-detected eggs per female worm and measured diagnostic aggregation parameter, respectively (all assumed to be independent of each other _a priori_). Kato-katz and urine filtration counts typically follow a distribution which appears to be negative binomial in shape. By computing the mean diagnostically-detected egg count $\\hat{{\\sf e}}_{\\rm d}=\\lambda_{\\rm d}\\hat{{\\sf e}}$ from the transmission parameters $\\{ R_0(a), M (a,t_0),k,z,\\lambda_{\\rm d},k_{\\rm d}\\}$, the likelihood distribution which will be used for the inference of these parameters is therefore likely to be well-approximated by\n",
    "\n",
    "$${\\cal L}[{\\cal D}\\vert  R_0(a), M (a,t_0),k,z,\\lambda_{\\rm d},k_{\\rm d} ] = \\prod_{\\forall {\\sf e}_i\\in {\\cal D}}{\\rm NB}\\bigg\\{ {\\sf e}_i; \\frac{\\lambda_{\\rm d}}{2}\\hat{{\\sf e}}[M(a,t),k,z],k_{\\rm d}\\bigg\\} \\,,$$\n",
    "\n",
    "where $M(a,t)$ is the age and time-dependent total mean worm burden which can be fully specified from $R_0(a)$, the other parameters, and the initial conditions $M (a,t_0)$. \n",
    "\n",
    "Note that one should refer to, e.g., Anderson & May, 1991 or [https://www.sciencedirect.com/science/article/pii/S002251931930445X ] for the motivations behind the calculation of the proportionality factor for the first moment of the egg count distribution $\\hat{{\\sf e}}$, which, for example, in the case of STH (fully polygamous male worms) is analytic (it is not in the case of monogamous schistosomes)\n",
    "\n",
    "$$\\hat{{\\sf e}}_{\\rm STH}[M(a,t),k,t] = \\phi [M(a,t);k,z]\\, f [M(a,t);k,z] M(a,t)$$\n",
    "\n",
    "$$f[M(a,t);k,z] \\equiv \\left[ 1+(1-z)\\frac{M(a,t)}{k}\\right]^{-(k+1)} $$\n",
    "\n",
    "$$\\phi [M(a,t);k,z] \\equiv 1-\\left[ \\frac{1+(1-z)M(a,t)/k}{1+(2-z)M(a,t)/(2k)}\\right]^{k+1} \\,.$$\n",
    "\n",
    "From Anderson & May, 1991, the mean field (or 'deterministic') transmission dynamics of the helminth infections considered here (STH and schistosomes) with age structure can be described by the following system \n",
    "\n",
    "$$\\frac{\\partial M}{\\partial t} + \\frac{\\partial M}{\\partial a} = \\Lambda (a,t) - \\mu_1 M(a,t) \\,.$$\n",
    "\n",
    "This equation may be converted to a differential equation with respect to time only, while discretising the mean worm burden into age bins $\\{ a_i\\}$, by integrating over $a$ using a survival rate kernel $S(a)$ like so\n",
    "\n",
    "$$M_i(t) \\equiv M(a_i,t) = \\frac{\\int^{a_{i+1/2}}_{a_{i-1/2}}{\\rm d}a \\, M(a,t) S(a)}{\\int^{\\infty}_{0}{\\rm d}a S(a)} \\,.$$\n",
    "\n",
    "Choosing the $S(a) = e^{-\\mu a}$ (where $\\mu$ is the human death rate) and assuming an age-constant $\\Lambda (a_i,t)$ within the bin (as we have assumed before in the fitting procedure), one may obtain the following first-order differential equation corresponding to the dynamics in the $i$-th age bin\n",
    "\n",
    "$$\\frac{{\\rm d} M_i}{{\\rm d} t} = \\Lambda (a_i,t) - (\\mu + \\mu_1)M_i(t) \\,. \\qquad \\qquad (1)$$\n",
    "\n",
    "In order to obtain this equation above, we have assumed that the boundary flux between age bins must vanish\n",
    "\n",
    "$$\\left.\\frac{\\partial M_i}{\\partial a} \\right\\vert_{a_{i+1/2}}=0 \\,,$$\n",
    "\n",
    "due to an approximated instananeous change in the worm burden for the individual (as a consequence of individuals changing force of infection $\\Lambda (a_i,t) \\rightarrow \\Lambda (a_{i+1},t)$) - note that this also sets the other boundary flux\n",
    "\n",
    "$$\\left.\\frac{\\partial M_i}{\\partial a} \\right\\vert_{a_{i-1/2}}=\\left.\\frac{\\partial M_{i-1}}{\\partial a} \\right\\vert_{a_{i-1/2}}=\\left.\\frac{\\partial M_{(i-1)}}{\\partial a} \\right\\vert_{a_{(i-1)+1/2}}=0 \\,.$$\n",
    "\n",
    "As a side note: in a fully stochastic individual-based model, the change in the expected worm burden will occur over a timescale of $1/\\mu_1$, so ensuring that the age bin widths are wider than this timescale is a necessity for this approximation remain accurate. Note also that the birth rate into the first age bin should be set to $\\mu$ to match the simulation.\n",
    "\n",
    "Similarly, one may obtain an equation for the age-binned dynamics (see [https://www.medrxiv.org/content/10.1101/2019.12.17.19013490v1 ]) of the force of infection $\\Lambda_i \\equiv \\Lambda (a_i,t)$ \n",
    "\n",
    "$$\\frac{{\\rm d}\\Lambda_i}{{\\rm d}t} = \\mu_2(\\mu + \\mu_1)R_{0,i}\\bigg\\{ \\sum_{j=1}^{N_a}\\frac{N_j}{N_{\\rm tot}}\\hat{{\\sf e}}[M_j(t),k,z] \\bigg\\} - \\mu_2 \\Lambda_i\\,. \\qquad \\qquad (2)$$\n",
    "\n",
    "The solution to the system $(1)$ and $(2)$ can hence be inserted into the negative binomial likelihood ${\\rm NB}\\{ {\\sf e}_i; \\lambda_{\\rm d}\\hat{{\\sf e}}[M(a,t),k,z],k_{\\rm d}\\}$ to perform the inference. Note also that given the rapid equilibration of the infectious reservoir ${\\rm d}\\Lambda_i /{\\rm d}t\\rightarrow 0$, we need not specify $\\Lambda_i(t_0)$ independently in the inference, but instead may identify \n",
    "\n",
    "$$\\Lambda_i(t) = (\\mu + \\mu_1)R_{0,i}\\sum_{j=1}^{N_a}\\frac{N_j}{N_{\\rm tot}} \\, \\hat{{\\sf e}}[M_j(t),k,z] \\,,$$\n",
    "\n",
    "where $N_i$ is the number of people within an age group (and $N_{\\rm tot}$ in total) and $R_{0,i}=R_0(a_i)$ is an age-dependent coefficient which contributes to the basic reproduction number in this bin. By inserting $\\Lambda (a_i,t)$ into the equation for ${\\rm d} M_i/{\\rm d} t$ above, the nonlinear dynamical system of equations that this generates is \n",
    "\n",
    "$$\\frac{{\\rm d} M_{i}}{{\\rm d} t} = (\\mu +\\mu_1) R_{0,i}\\sum_{j=1}^{N_a}\\left\\{ \\frac{N_j}{N_{\\rm tot}}\\, \\hat{{\\sf e}}[M_j(t),k,z] \\right\\} - (\\mu +\\mu_1)M_i(t) \\,,$$\n",
    "\n",
    "where value of the overall $R_0$ may be obtained through the relation\n",
    "\n",
    "$$R_{0}=\\frac{1}{N_{\\rm tot}}\\sum^{N_a}_{i=1} N_iR_{0,i} \\,.$$\n",
    "\n",
    "Note also that, at equilibrium $M(a_i,t)\\rightarrow M(a_i)\\,\\, \\forall i$, the value of $R_0$ is constrained to\n",
    "\n",
    "$$R_{0} = \\frac{\\sum_{i=1}^{N_a} N_iM_i}{\\sum_{j=1}^{N_a} N_j \\,\\hat{{\\sf e}}(M_j,k,z)} \\,.$$\n",
    "\n",
    "To include migration between clusters in the inference, the ${\\rm d}\\Lambda_i/{\\rm d}t$ equation above would be modified by the expectations of compound Poisson processes modelling the net ingoing and outgoing eggs/larvae (see: [https://www.sciencedirect.com/science/article/pii/S002251931930445X]). We will not handle this case here though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup with mock data\n",
    "\n",
    "First we must import `helmpy` and the other modules necessary for the inference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_to_helmpy = '/Users/Rob/work/helmpy' # Give your path to helmpy here\n",
    "sys.path.append(path_to_helmpy + '/source/') \n",
    "from helmpy import helmpy\n",
    "\n",
    "# These modules are not necessary to run helmpy alone but will be useful for our demonstrations\n",
    "\n",
    "# LEAVE THESE IMPORTS COMMENTED AS THEY ARE FOR PRODUCING LaTeX-STYLE FIGURES ONLY\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "#mpl.rc('font',family='CMU Serif')\n",
    "#mpl.rcParams['xtick.labelsize'] = 15\n",
    "#mpl.rcParams['ytick.labelsize'] = 15\n",
    "#mpl.rcParams['axes.labelsize'] = 20\n",
    "#from matplotlib import rc\n",
    "#rc('text',usetex=True)\n",
    "#rc('text.latex',preamble=r'\\usepackage{mathrsfs}')\n",
    "#rc('text.latex',preamble=r'\\usepackage{sansmath}')\n",
    "# LEAVE THESE IMPORTS COMMENTED AS THEY ARE FOR PRODUCING LaTeX-STYLE FIGURES ONLY\n",
    "\n",
    "import numpy as np\n",
    "import scipy.special as spec\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee as mc\n",
    "import corner\n",
    "from getdist import plots,MCSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and make up some mock (here we shall assume full Kato-Katz intensity counts) data in 2 age categories to use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean egg counts from data\n",
    "meanegg_age1 = 10.0\n",
    "meanegg_age2 = 20.0\n",
    "# Variance of egg count data\n",
    "varegg = 3000.0\n",
    "# Kato-Katz samples drawn for each age group\n",
    "kksamps_age1 = np.random.negative_binomial(meanegg_age1**2.0/np.abs(varegg-meanegg_age1),meanegg_age1/varegg,size=150)\n",
    "kksamps_age2 = np.random.negative_binomial(meanegg_age2**2.0/np.abs(varegg-meanegg_age2),meanegg_age2/varegg,size=150)\n",
    "# Combine Kato-Katz samples into list\n",
    "kksamps = [kksamps_age1,kksamps_age2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a function which starts a `helmpy` STH instance, takes in parameters that we want to sample from the posterior distribution (see ${\\cal P}[ R_{0,i}, M_i (t_0),k,z,\\lambda_{\\rm d},k_{\\rm d}  \\vert {\\cal D}]$ above) and outputs the mean worm burdens from the mean field model (see helmpy_examples.ipynb for a more pedagogical `helmpy` instance setup). Of course, it will not be possible to infer all of these parameters from the Kato-Katz data alone, so we shall make some prior assumptions (i.e., Dirac delta priors) for their values in some cases. In particular (see [https://parasitesandvectors.biomedcentral.com/articles/10.1186/s13071-019-3686-2 ]) here for STH we will assume $\\lambda_{\\rm d} = 3.05$ and $z=e^{-\\gamma}=e^{-0.005}\\simeq 0.995$. We will also keep things simple by fixing the $M_i(t_0)$ values to finite values and run the simulation long enough to achieve equilibrium (10 years). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create STH function for proportionality factor of egg count mean\n",
    "def ec(M,k,z):\n",
    "    # See Anderson & May, 1991\n",
    "    phi = 1.0 - (((1.0+((1.0-z)*M/k))/(1.0+((2.0-z)*M/(2.0*k))))**(k+1.0))\n",
    "    f = (1.0+((1.0-z)*M/k))**(-(k+1.0))\n",
    "    return M*phi*f\n",
    "\n",
    "# Create mean worm burden generating function for an arbitrary number of age bins\n",
    "def M_func(params):\n",
    "    \n",
    "    # Extract the posterior parameters\n",
    "    [lnR0s, lnk, lnkd] = params\n",
    "    \n",
    "    # Get the number of age bins\n",
    "    Na = len(lnR0s)\n",
    "    \n",
    "    # Set arbitrary finite values - may need to check for sensitivity\n",
    "    lnM0s = 3.0*np.ones(Na)\n",
    "    \n",
    "    hp = helmpy('STH',path_to_helmpy,suppress_terminal_output=True)  # New helmpy instance\n",
    "    hp.parameter_dictionary['mu'] = [0.014]*Na                       # Human death rate (per year)\n",
    "    hp.parameter_dictionary['mu1'] = [0.5]*Na                        # Adult worm death rate (per year)\n",
    "    hp.parameter_dictionary['mu2'] = [26.0]*Na                       # Reservoir (eggs and larvae) death rate \n",
    "    hp.parameter_dictionary['R0'] = np.exp(lnR0s).tolist()           # Basic reproduction number within grouping\n",
    "    hp.parameter_dictionary['k'] = [np.exp(lnk)]*Na                  # Inverse-clumping factor within grouping\n",
    "    hp.parameter_dictionary['gam'] = [0.005]*Na                      # Density dependent fecundity: z = exp(-gam)\n",
    "    hp.parameter_dictionary['Np'] = [250]*Na                         # Number of people within grouping   \n",
    "    hp.parameter_dictionary['spi'] = [1]*Na                          # Spatial index number of grouping\n",
    "    \n",
    "    # Set to arbitrary finite value\n",
    "    hp.initial_conditions['M'] = np.exp(lnM0s).tolist()              # Initial mean total worm burden within group\n",
    "    \n",
    "    # Set to arbitrary finite value (rapid equilibriation anyway)\n",
    "    mu1 = np.asarray(hp.parameter_dictionary['mu1'])\n",
    "    Lameq = mu1*np.exp(lnR0s)*np.exp(lnM0s)\n",
    "    hp.initial_conditions['FOI'] = Lameq.tolist()                    # Initial force of infection within grouping\n",
    "    \n",
    "    runtime = 10.0                                                   # Set the total time of the run in years\n",
    "    do_nothing_timescale = 0.02                                      # Set a timescale (in years) short enough \n",
    "    fname = 'output'                                                 # File name if we were outputting to file\n",
    "    \n",
    "    # Output endpoint M values\n",
    "    return hp.run_meanfield(runtime,do_nothing_timescale,fname,just_a_function=True,output_mean_groups=True)[-1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can now create a likelihood function ${\\cal L}[{\\cal D}\\vert R_{0,i}, M_i (t_0),k,z,\\lambda_{\\rm d},k_{\\rm d} ]$ for our MCMC sampler..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to define a custom log negative binomial function because of definition ambiguities...\n",
    "def lognegbinom(n,k,m):\n",
    "    \n",
    "    # Set mean and variance\n",
    "    mean, var = m, m + (m**2.0/k)\n",
    "    \n",
    "    # Negative binomial loglikelihood with mean and variance specified\n",
    "    sol = np.log((spec.gamma(((mean**2.0)/(var-mean))+n)/\\\n",
    "                (spec.gamma(n+1.0)*spec.gamma(((mean**2.0)/(var-mean)))))*\\\n",
    "                ((mean/var)**((((mean**2.0)/(var-mean)))))*(((var-mean)/var)**n))\n",
    "    \n",
    "    # If any overflow problems, use large argument expansion of log negative binomial\n",
    "    overflow_vals = (np.isnan(sol) | np.isinf(sol))\n",
    "    overflow_n = n[overflow_vals]\n",
    "    sol[overflow_vals] = np.log((((1.0-(mean/var))**overflow_n)*(overflow_n**((mean**2.0/\\\n",
    "                                (var-mean))-1.0))*((mean/var)**(mean**2.0/\\\n",
    "                                (var-mean)))/(spec.gamma(mean**2.0/(var-mean)))))  \n",
    "    \n",
    "    # Avoiding further pathologies\n",
    "    if (var < mean): sol = -np.inf\n",
    "    sol[np.isnan(sol)] = -np.inf\n",
    "    \n",
    "    # Return \n",
    "    return sol\n",
    "\n",
    "# Define log-likelihood function\n",
    "def loglike(params):\n",
    "    \n",
    "    # Find the number of age bins from data by length of data list\n",
    "    Na = len(kksamps)\n",
    "    \n",
    "    # Extract parameters\n",
    "    lnR0s, lnk, lnkd = params[:Na], params[Na], params[Na+1]    \n",
    "    \n",
    "    # Specify sampling prior domain restrictions\n",
    "    if (lnk > 5.0) or (lnkd > 5.0) or (lnk < -10.0) or (lnkd < -10.0) \\\n",
    "    or np.any(lnR0s<-5.0) or np.any(lnR0s>5.0):\n",
    "        return -np.inf\n",
    "    else:      \n",
    "        # Run dynamics to get M\n",
    "        Mt = M_func([lnR0s, lnk, lnkd])\n",
    "        \n",
    "        # We are assuming STH here so the mean egg count is calculable from the first moment...\n",
    "        lambda_d = 3.05\n",
    "        ecm = (lambda_d/2.0)*ec(Mt,np.exp(lnk),np.exp(-0.005))\n",
    "        \n",
    "        # Sum over log-likelihood for the Kato-Katz data in each age bin \n",
    "        return sum([np.sum(lognegbinom(kksamps[si],np.exp(lnkd),ecm[si])) for si in range(0,Na)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter inference and visualisation\n",
    "\n",
    "Now to run the sampler (this can be quite slow for a large number of iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise number of walkers and iterations\n",
    "nwalkers = 100\n",
    "niterations = 250\n",
    "\n",
    "# Initialise ensemble of walkers\n",
    "init_ensemble = []\n",
    "\n",
    "# Add lnR0s to ensemble\n",
    "init_ensemble.append(np.random.normal(0.5,0.5,size=nwalkers)) \n",
    "init_ensemble.append(np.random.normal(2.0,0.5,size=nwalkers)) \n",
    "# Add lnk to ensemble\n",
    "init_ensemble.append(np.random.normal(-2.5,0.5,size=nwalkers))\n",
    "# Add lnkd to ensemble\n",
    "init_ensemble.append(np.random.normal(-2.0,0.5,size=nwalkers))\n",
    "# Reshape for input into emcee\n",
    "init_ensemble = np.asarray(init_ensemble).T\n",
    "\n",
    "# Run ensemble MC sampler - feel free to substitute another method!\n",
    "sampler = mc.EnsembleSampler(nwalkers, 4, loglike)\n",
    "sampler.run_mcmc(init_ensemble, niterations, progress=True)\n",
    "samples = sampler.chain[:, 50:, :].reshape((-1, 4))\n",
    "\n",
    "# Quick corner plot of samples - good for diagnosing problems\n",
    "labels =  ['lnR01','lnR02','lnk','lnkd']\n",
    "#corner.corner(samples,labels=labels)\n",
    "\n",
    "# Setup samples for getdist - nicer looking triangle plots!\n",
    "names = ['lnR01','lnR02','lnk','lnkd']\n",
    "gsamples = MCSamples(samples=samples,names=names,labels=labels)\n",
    "\n",
    "# Triangle plot\n",
    "g = plots.get_subplot_plotter()\n",
    "g.settings.legend_fontsize=15\n",
    "g.settings.axes_fontsize=15\n",
    "g.settings.lab_fontsize=15\n",
    "g.triangle_plot(gsamples, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this procedure may need to be performed many times and the chain diagnostics should be examined to make sure the sampling is converging. Note that the code above is pretty slow and would run faster with different samplers, but it does the job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Posterior predictive forecasting with the samples\n",
    "\n",
    "Once the samples have been obtained, forecasting with a full stochastic individual-based simulation can be achieved by using the `helmpy.run_full_stoch` method with `helmpy.posterior_samples`. We do this like so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the last 250 samples for demonstration\n",
    "samples_to_run = samples[-250:]\n",
    "\n",
    "# Number of age bins\n",
    "Na = 2\n",
    "\n",
    "# Set arbitrary finite values - may need to check for sensitivity\n",
    "lnM0s = 3.0*np.ones(Na)\n",
    "\n",
    "# New helmpy instance\n",
    "hp = helmpy('STH',path_to_helmpy)          \n",
    "\n",
    "# Set to arbitrary finite value\n",
    "hp.initial_conditions['M'] = np.exp(lnM0s).tolist()              # Initial mean total worm burden within group\n",
    "hp.parameter_dictionary['mu'] = [0.014]*Na                       # Human death rate (per year)\n",
    "hp.parameter_dictionary['mu1'] = [0.5]*Na                        # Adult worm death rate (per year)\n",
    "hp.parameter_dictionary['mu2'] = [26.0]*Na                       # Reservoir (eggs and larvae) death rate \n",
    "hp.parameter_dictionary['gam'] = [0.005]*Na                      # Density dependent fecundity: z = exp(-gam)\n",
    "hp.parameter_dictionary['Np'] = [250]*Na                         # Number of people within grouping   \n",
    "hp.parameter_dictionary['spi'] = [1]*Na                          # Spatial index number of grouping \n",
    "\n",
    "# Set the number of realisations\n",
    "realisations = 250                            \n",
    "\n",
    "# Set the posterior samples to run in the prediction simulation\n",
    "hp.posterior_samples['ksamps'] = [np.exp(samples_to_run[:,Na])]*Na                   # Initialisation with k samples\n",
    "hp.posterior_samples['R0samps'] = [np.exp(samples_to_run[:,i]) for i in range(0,Na)] # Initialisation with R0 samples\n",
    "\n",
    "# Set to arbitrary finite value (rapid equilibriation anyway)\n",
    "mu1 = hp.parameter_dictionary['mu1']\n",
    "hp.posterior_samples['Lamsamps'] = [mu1[i]*hp.posterior_samples['R0samps'][i]*np.exp(lnM0s)[i] for i in range(0,Na)]\n",
    "\n",
    "# Run the stochastic simulation for the results\n",
    "output_filename = 'default_example'   # Set a filename for the data to be output\n",
    "runtime = 20.0 \n",
    "do_nothing_timescale = 0.01 \n",
    "hp.run_full_stoch(runtime,realisations,do_nothing_timescale,'detfit_' + output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output can also be found in the usual place..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load plot data\n",
    "forecast_runs = np.loadtxt(path_to_helmpy + '/data/detfit_' + output_filename + '.txt')\n",
    "\n",
    "# Generate plot for mean and 68% credible intervals\n",
    "plt.plot(forecast_runs.T[0],forecast_runs.T[1],color='r')\n",
    "plt.plot(forecast_runs.T[0],forecast_runs.T[3],color='r')\n",
    "plt.plot(forecast_runs.T[0],forecast_runs.T[4],color='r')\n",
    "plt.fill_between(forecast_runs.T[0],forecast_runs.T[4],forecast_runs.T[3],color='r',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the deterministic fitting code in conjunction with stochastic simulations is a convenient way to generate predictions for a whole range of scenarios, especially when used in conjunction with the other features within `helmpy`. Note, however, there are important limitations to this method that were discussed at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
