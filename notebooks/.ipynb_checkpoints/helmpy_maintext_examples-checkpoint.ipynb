{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive notebook of plots in the main text \n",
    "\n",
    "In this notebook we run through generating the plots used in the main text of XXXX.\n",
    "To do: \n",
    "1. UES Migration endpoint prevalence contour plots for 100, 350, 1000 people doing migrations from C1 -> C2 and C1 -> C1\n",
    "2. Treatment plot can just be a single example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_to_helmpy = '/Users/Rob/work/helmpy' # Give your path to helmpy here\n",
    "sys.path.append(path_to_helmpy + '/source/') \n",
    "from helmpy import helmpy\n",
    "\n",
    "# These modules are not necessary to run helmpy alone but will be useful for our demonstrations\n",
    "\n",
    "# LEAVE THESE IMPORTS COMMENTED AS THEY ARE FOR PRODUCING LaTeX-STYLE FIGURES ONLY\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "#mpl.rc('font',family='CMU Serif')\n",
    "#mpl.rcParams['xtick.labelsize'] = 15\n",
    "#mpl.rcParams['ytick.labelsize'] = 15\n",
    "#mpl.rcParams['axes.labelsize'] = 20\n",
    "#from matplotlib import rc\n",
    "#rc('text',usetex=True)\n",
    "#rc('text.latex',preamble=r'\\usepackage{mathrsfs}')\n",
    "#rc('text.latex',preamble=r'\\usepackage{sansmath}')\n",
    "# LEAVE THESE IMPORTS COMMENTED AS THEY ARE FOR PRODUCING LaTeX-STYLE FIGURES ONLY\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plots 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                                              # and realisations after a specified number of steps in time  \\nhp.run_full_stoch(         \\n                  runtime,          \\n                  realisations,  \\n                  do_nothing_timescale,\\n                  output_filename,  \\n                  timesteps_snapshot=output_timesteps\\n                  )\\n\\nhp.run_meanfield_stoch(         \\n                       runtime, \\n                       realisations,\\n                       do_nothing_timescale,                \\n                       'meanfield_stoch_' + output_filename,\\n                       timesteps_snapshot=output_timesteps\\n                       )\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = helmpy(\n",
    "            'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "            path_to_helmpy,                     # Set the path to the working directory\n",
    "            suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "            )  \n",
    "\n",
    "hp.parameter_dictionary['mu'] = [0.014,0.014,0.014]   # Human death rate (per year)\n",
    "hp.parameter_dictionary['mu1'] = [0.5,0.5,0.5]        # Adult worm death rate (per year)\n",
    "hp.parameter_dictionary['mu2'] = [26.0,26.0,26.0]     # Reservoir (eggs and larvae) death rate (per year)\n",
    "hp.parameter_dictionary['R0'] = [2.1,2.1,2.1]         # Basic reproduction number within grouping\n",
    "hp.parameter_dictionary['k'] = [0.5,0.5,0.5]          # Inverse-clumping factor within grouping\n",
    "hp.parameter_dictionary['gam'] = [0.08,0.08,0.08]     # Density dependent fecundity: z = exp(-gam)\n",
    "hp.parameter_dictionary['Np'] = [100,350,1000]        # Number of people within grouping   \n",
    "hp.parameter_dictionary['spi'] = [1,2,3]              # Spatial index number of grouping\n",
    "\n",
    "hp.initial_conditions['M'] = [2.1,2.1,2.1]            # Initial mean total worm burden within grouping\n",
    "hp.initial_conditions['FOI'] = [1.1,1.1,1.1]          # Initial force of infection (per year) within grouping\n",
    "\n",
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time  \n",
    "hp.run_full_stoch(         \n",
    "                  runtime,          \n",
    "                  realisations,  \n",
    "                  do_nothing_timescale,\n",
    "                  output_filename,  \n",
    "                  timesteps_snapshot=output_timesteps\n",
    "                  )\n",
    "\n",
    "hp.run_meanfield_stoch(         \n",
    "                       runtime, \n",
    "                       realisations,\n",
    "                       do_nothing_timescale,                \n",
    "                       'meanfield_stoch_' + output_filename,\n",
    "                       timesteps_snapshot=output_timesteps\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_meanfield_stoch_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_stoch_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[1],'--',color='r')\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],'--',color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 3\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[3],'--',color='g')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[7],color='r')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[10],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[8],color='b')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[11],color='b')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 3\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[9],color='g')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[12],color='g')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,4.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "#plt.legend(fontsize = 12, loc = 9)\n",
    "plt.savefig(path_to_helmpy + '/plots/meanfield_stoch_comp_1.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_meanfield_stoch_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_stoch_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 1\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[1],'--',color='r')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 2\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[2],'--',color='b')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 3\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[3],'--',color='g')\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 1\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[7],color='r')\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[10],color='r')\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 2\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[8],color='b')\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[11],color='b')\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 3\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[9],color='g')\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[12],color='g')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,4.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "#plt.legend(fontsize = 12, loc = 9)\n",
    "plt.savefig(path_to_helmpy + '/plots/meanfield_stoch_comp_2.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plots 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                                              # and realisations after a specified number of steps in time  \\nhp.run_full_stoch(         \\n                  runtime,          \\n                  realisations,  \\n                  do_nothing_timescale,\\n                  output_filename + '2',  \\n                  timesteps_snapshot=output_timesteps\\n                  )\\n\\nhp.run_meanfield_stoch(         \\n                       runtime, \\n                       realisations,\\n                       do_nothing_timescale,                \\n                       'meanfield_stoch_' + output_filename + '2',\\n                       timesteps_snapshot=output_timesteps\\n                       )\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = helmpy(\n",
    "            'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "            path_to_helmpy,                     # Set the path to the working directory\n",
    "            suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "            )  \n",
    "\n",
    "hp.parameter_dictionary['mu'] = [0.014,0.014,0.014]   # Human death rate (per year)\n",
    "hp.parameter_dictionary['mu1'] = [0.5,0.5,0.5]        # Adult worm death rate (per year)\n",
    "hp.parameter_dictionary['mu2'] = [26.0,26.0,26.0]     # Reservoir (eggs and larvae) death rate (per year)\n",
    "hp.parameter_dictionary['R0'] = [3.5,3.5,3.5]         # Basic reproduction number within grouping\n",
    "hp.parameter_dictionary['k'] = [0.3,0.3,0.3]          # Inverse-clumping factor within grouping\n",
    "hp.parameter_dictionary['gam'] = [0.08,0.08,0.08]     # Density dependent fecundity: z = exp(-gam)\n",
    "hp.parameter_dictionary['Np'] = [100,350,1000]        # Number of people within grouping   \n",
    "hp.parameter_dictionary['spi'] = [1,2,3]              # Spatial index number of grouping\n",
    "\n",
    "hp.initial_conditions['M'] = [2.9,2.9,2.9]            # Initial mean total worm burden within grouping\n",
    "hp.initial_conditions['FOI'] = [1.25,1.25,1.25]       # Initial force of infection (per year) within grouping\n",
    "\n",
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time  \n",
    "hp.run_full_stoch(         \n",
    "                  runtime,          \n",
    "                  realisations,  \n",
    "                  do_nothing_timescale,\n",
    "                  output_filename + '2',  \n",
    "                  timesteps_snapshot=output_timesteps\n",
    "                  )\n",
    "\n",
    "hp.run_meanfield_stoch(         \n",
    "                       runtime, \n",
    "                       realisations,\n",
    "                       do_nothing_timescale,                \n",
    "                       'meanfield_stoch_' + output_filename + '2',\n",
    "                       timesteps_snapshot=output_timesteps\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '2' + '.txt')\n",
    "example_meanfield_stoch_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_stoch_' \\\n",
    "                                                              + output_filename + '2' + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[1],'--',color='r')\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],'--',color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 3\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[3],'--',color='g')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[7],color='r')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[10],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[8],color='b')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[11],color='b')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 3\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[9],color='g')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[12],color='g')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([2.0,7.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "#plt.legend(fontsize = 12, loc = 9)\n",
    "plt.savefig(path_to_helmpy + '/plots/meanfield_stoch_comp_3.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '2' + '.txt')\n",
    "example_meanfield_stoch_data = np.loadtxt(path_to_helmpy + '/data/' + 'meanfield_stoch_' \\\n",
    "                                                              + output_filename + '2' + '.txt')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 1\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[1],'--',color='r')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 2\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[2],'--',color='b')\n",
    "\n",
    "# Mean of mean-field stochastic ensemble in cluster 3\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[3],'--',color='g')\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 1\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[7],color='r')\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[10],color='r')\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 2\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[8],color='b')\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[11],color='b')\n",
    "\n",
    "# 68% CLs of mean-field stochastic ensemble in cluster 3\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[9],color='g')\n",
    "plt.plot(example_meanfield_stoch_data.T[0],example_meanfield_stoch_data.T[12],color='g')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([2.0,7.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "#plt.legend(fontsize = 12, loc = 9)\n",
    "plt.savefig(path_to_helmpy + '/plots/meanfield_stoch_comp_4.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                                              # and realisations after a specified number of steps in time  \\nhp.run_full_stoch(         \\n                  runtime,          \\n                  realisations,  \\n                  do_nothing_timescale,\\n                  output_filename + 'withage',  \\n                  timesteps_snapshot=output_timesteps\\n                  )\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = helmpy(\n",
    "            'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "            path_to_helmpy,                     # Set the path to the working directory\n",
    "            suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "            )  \n",
    "\n",
    "hp.parameter_dictionary['mu'] = [0.014,0.014,0.014,0.014,0.014,0.014]  # Human death rate (per year)\n",
    "hp.parameter_dictionary['mu1'] = [0.5,0.5,0.5,0.5,0.5,0.5]             # Adult worm death rate (per year)\n",
    "hp.parameter_dictionary['mu2'] = [26.0,26.0,26.0,26.0,26.0,26.0]       # Reservoir (eggs and larvae) death rate \n",
    "hp.parameter_dictionary['R0'] = [1.93,5.8,1.93,5.8,1.93,5.8]           # Basic reproduction number within grouping\n",
    "hp.parameter_dictionary['k'] = [0.3,0.3,0.3,0.3,0.3,0.3]               # Inverse-clumping factor within grouping\n",
    "hp.parameter_dictionary['gam'] = [0.08,0.08,0.08,0.08,0.08,0.08]       # Density dependent fecundity: z = exp(-gam)\n",
    "hp.parameter_dictionary['Np'] = [50,50,175,175,500,500]                # Number of people within grouping   \n",
    "hp.parameter_dictionary['spi'] = [1,1,2,2,3,3]                         # Spatial index number of grouping\n",
    "\n",
    "hp.initial_conditions['M'] = [2.9,2.9,2.9,2.9,2.9,2.9]                 # Initial mean total worm burden \n",
    "hp.initial_conditions['FOI'] = [1.25,1.25,1.25,1.25,1.25,1.25]         # Initial force of infection (per year) \n",
    "\n",
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time  \n",
    "hp.run_full_stoch(         \n",
    "                  runtime,          \n",
    "                  realisations,  \n",
    "                  do_nothing_timescale,\n",
    "                  output_filename + 'withage',  \n",
    "                  timesteps_snapshot=output_timesteps\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + 'withage' + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[1],'--',color='r')\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],'--',color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 3\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[3],'--',color='g')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[7],color='r')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[10],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[8],color='b')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[11],color='b')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 3\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[9],color='g')\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[12],color='g')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([2.0,7.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "#plt.legend(fontsize = 12, loc = 9)\n",
    "plt.savefig(path_to_helmpy + '/plots/meanfield_stoch_comp_5.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot stack 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 5000\n",
    "numinds = [1,2] # For 1% and 2% prevalence\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [2.1,3.5]       \n",
    "hppre.parameter_dictionary['k'] = [0.5,0.3]            \n",
    "hppre.parameter_dictionary['Np'] = [100,100]       \n",
    "hppre.parameter_dictionary['spi'] = [1,2]          \n",
    "hppre.initial_conditions['M'] = [2.35,5.2] # At equilibrium        \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,1):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Ngrower_samples = []\n",
    "    for n in range(0,len(numinds)):\n",
    "        numind = numinds[n]\n",
    "        \n",
    "        for ndraw in range(0,number_of_samples):\n",
    "            reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,\\\n",
    "                                                       hppre.parameter_dictionary['Np'][0],numind)\n",
    "            pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                1.0/hppre.parameter_dictionary['k'][i],size=hppre.parameter_dictionary['Np'][0])\n",
    "            Ngrower_samples.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))) \n",
    "        \n",
    "        if n == 0: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),color='r',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='r',alpha=0.3)\n",
    "        if n == 1: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),'--',color='r',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='r',alpha=0.3)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "axes.set_xlim([0.0,5.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_dist_100a.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 5000\n",
    "numinds = [1,2] # For 1% and 2% prevalence\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [2.1,3.5]       \n",
    "hppre.parameter_dictionary['k'] = [0.5,0.3]            \n",
    "hppre.parameter_dictionary['Np'] = [100,100]       \n",
    "hppre.parameter_dictionary['spi'] = [1,2]          \n",
    "hppre.initial_conditions['M'] = [2.35,5.2] # At equilibrium        \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(1,2):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Ngrower_samples = []\n",
    "    for n in range(0,len(numinds)):\n",
    "        numind = numinds[n]\n",
    "        \n",
    "        for ndraw in range(0,number_of_samples):\n",
    "            reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,\\\n",
    "                                                       hppre.parameter_dictionary['Np'][0],numind)\n",
    "            pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                1.0/hppre.parameter_dictionary['k'][i],size=hppre.parameter_dictionary['Np'][0])\n",
    "            Ngrower_samples.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))) \n",
    "        \n",
    "        if n == 0: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),color='r',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='r',alpha=0.3)\n",
    "        if n == 1: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),'--',color='r',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='r',alpha=0.3)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "axes.set_xlim([0.0,5.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_dist_100b.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 5000\n",
    "numinds = [4,7] # For 1% and 2% prevalence\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [2.1,3.5]       \n",
    "hppre.parameter_dictionary['k'] = [0.5,0.3]            \n",
    "hppre.parameter_dictionary['Np'] = [350,350]       \n",
    "hppre.parameter_dictionary['spi'] = [1,2]          \n",
    "hppre.initial_conditions['M'] = [2.35,5.2] # At equilibrium        \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,1):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Ngrower_samples = []\n",
    "    for n in range(0,len(numinds)):\n",
    "        numind = numinds[n]\n",
    "        \n",
    "        for ndraw in range(0,number_of_samples):\n",
    "            reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,\\\n",
    "                                                       hppre.parameter_dictionary['Np'][0],numind)\n",
    "            pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                1.0/hppre.parameter_dictionary['k'][i],size=hppre.parameter_dictionary['Np'][0])\n",
    "            Ngrower_samples.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))) \n",
    "        \n",
    "        if n == 0: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),color='b',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='b',alpha=0.3)\n",
    "        if n == 1: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),'--',color='b',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='b',alpha=0.3)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "axes.set_xlim([0.0,5.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_dist_350a.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 10000\n",
    "numinds = [4,7] # For 1% and 2% prevalence\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [2.1,3.5]       \n",
    "hppre.parameter_dictionary['k'] = [0.5,0.3]            \n",
    "hppre.parameter_dictionary['Np'] = [350,350]       \n",
    "hppre.parameter_dictionary['spi'] = [1,2]          \n",
    "hppre.initial_conditions['M'] = [2.35,5.2] # At equilibrium        \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(1,2):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Ngrower_samples = []\n",
    "    for n in range(0,len(numinds)):\n",
    "        numind = numinds[n]\n",
    "        \n",
    "        for ndraw in range(0,number_of_samples):\n",
    "            reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,\\\n",
    "                                                       hppre.parameter_dictionary['Np'][0],numind)\n",
    "            pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                1.0/hppre.parameter_dictionary['k'][i],size=hppre.parameter_dictionary['Np'][0])\n",
    "            Ngrower_samples.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))) \n",
    "        \n",
    "        if n == 0: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),color='b',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='b',alpha=0.3)\n",
    "            out1 = out/max(out)\n",
    "        if n == 1: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),'--',color='b',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='b',alpha=0.3)\n",
    "            plt.fill_between([0,1], out1[:2], (out/max(out))[:2], color='b',alpha=0.3) # Fix to colouring\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "axes.set_xlim([0.0,5.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_dist_350b.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 5000\n",
    "numinds = [10,20] # For 1% and 2% prevalence\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [2.1,3.5]       \n",
    "hppre.parameter_dictionary['k'] = [0.5,0.3]            \n",
    "hppre.parameter_dictionary['Np'] = [1000,1000]       \n",
    "hppre.parameter_dictionary['spi'] = [1,2]          \n",
    "hppre.initial_conditions['M'] = [2.35,5.2] # At equilibrium        \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,1):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Ngrower_samples = []\n",
    "    for n in range(0,len(numinds)):\n",
    "        numind = numinds[n]\n",
    "        \n",
    "        for ndraw in range(0,number_of_samples):\n",
    "            reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,\\\n",
    "                                                       hppre.parameter_dictionary['Np'][0],numind)\n",
    "            pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                1.0/hppre.parameter_dictionary['k'][i],size=hppre.parameter_dictionary['Np'][0])\n",
    "            Ngrower_samples.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))) \n",
    "        \n",
    "        if n == 0: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),color='g',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='g',alpha=0.3)\n",
    "        if n == 1: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),'--',color='g',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='g',alpha=0.3)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "axes.set_xlim([0.0,5.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_dist_1000a.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 5000\n",
    "numinds = [10,20] # For 1% and 2% prevalence\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [2.1,3.5]       \n",
    "hppre.parameter_dictionary['k'] = [0.5,0.3]            \n",
    "hppre.parameter_dictionary['Np'] = [1000,1000]       \n",
    "hppre.parameter_dictionary['spi'] = [1,2]          \n",
    "hppre.initial_conditions['M'] = [2.35,5.2] # At equilibrium        \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(1,2):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Ngrower_samples = []\n",
    "    for n in range(0,len(numinds)):\n",
    "        numind = numinds[n]\n",
    "        \n",
    "        for ndraw in range(0,number_of_samples):\n",
    "            reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,\\\n",
    "                                                       hppre.parameter_dictionary['Np'][0],numind)\n",
    "            pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                1.0/hppre.parameter_dictionary['k'][i],size=hppre.parameter_dictionary['Np'][0])\n",
    "            Ngrower_samples.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))) \n",
    "        \n",
    "        if n == 0: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),color='g',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='g',alpha=0.3)\n",
    "        if n == 1: \n",
    "            out, edges = np.histogram(Ngrower_samples,bins=[0,1,2,3,4,5,5.5])\n",
    "            plt.plot([0,1,2,3,4,5],out/max(out),'--',color='g',linewidth=2)\n",
    "            plt.fill_between([0,1,2,3,4,5], 0.0, out/max(out), color='g',alpha=0.3)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.set_ylim([0.0,1.0])\n",
    "axes.set_xlim([0.0,5.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_dist_1000b.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot stack 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 10**5\n",
    "numinds = [i for i in range(1,10)]\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [np.random.uniform(2.0,4.0) for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['k'] = [10.0**(-np.random.uniform(0.0,4.0)) for i in range(0,100)]            \n",
    "hppre.parameter_dictionary['Np'] = [100 for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['spi'] = [i for i in range(0,100)]          \n",
    "hppre.initial_conditions['M'] = [np.random.uniform(2.0,5.0) for i in range(0,100)]          \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,len(hppre.parameter_dictionary['spi'])):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Efracclus = []\n",
    "    for numind in numinds:\n",
    "        reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,number_of_samples,numind)\n",
    "        pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                       1.0/hppre.parameter_dictionary['k'][i],size=number_of_samples)\n",
    "        Efracclus.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))/float(number_of_samples))   \n",
    "    plt.plot(np.asarray(numinds)/float(Npclusi),float(Npclusi)*np.asarray(Efracclus),'r',alpha=0.4)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.axvline(0.01,linestyle='--',color='k')\n",
    "axes.axvline(0.02,linestyle='--',color='k')\n",
    "axes.axhline(1.0,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'$N_{\\rm p}{\\rm E}(f_{\\rm max}^{>1})$')\n",
    "axes.set_xlabel(r'${\\sf p}$')\n",
    "axes.set_ylim([0.0,11.0])\n",
    "axes.set_xlim([0.0,0.03])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_100.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 10**5\n",
    "numinds = [i for i in range(1,11)]\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [np.random.uniform(2.0,4.0) for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['k'] = [10.0**(-np.random.uniform(0.0,4.0)) for i in range(0,100)]            \n",
    "hppre.parameter_dictionary['Np'] = [350 for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['spi'] = [i for i in range(0,100)]          \n",
    "hppre.initial_conditions['M'] = [np.random.uniform(2.0,5.0) for i in range(0,100)]          \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,len(hppre.parameter_dictionary['spi'])):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Efracclus = []\n",
    "    for numind in numinds:\n",
    "        reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,number_of_samples,numind)\n",
    "        pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                       1.0/hppre.parameter_dictionary['k'][i],size=number_of_samples)\n",
    "        Efracclus.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))/float(number_of_samples))   \n",
    "    plt.plot(np.asarray(numinds)/float(Npclusi),float(Npclusi)*np.asarray(Efracclus),'b',alpha=0.4)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.axvline(0.01,linestyle='--',color='k')\n",
    "axes.axvline(0.02,linestyle='--',color='k')\n",
    "axes.axhline(1.0,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'$N_{\\rm p}{\\rm E}(f_{\\rm max}^{>1})$')\n",
    "axes.set_xlabel(r'${\\sf p}$')\n",
    "axes.set_ylim([0.0,11.0])\n",
    "axes.set_xlim([0.0,0.03])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_350.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = 10**5\n",
    "numinds = [4*i for i in range(1,10)]\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [np.random.uniform(2.0,4.0) for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['k'] = [10.0**(-np.random.uniform(0.0,4.0)) for i in range(0,100)]            \n",
    "hppre.parameter_dictionary['Np'] = [1000 for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['spi'] = [i for i in range(0,100)]          \n",
    "hppre.initial_conditions['M'] = [np.random.uniform(2.0,5.0) for i in range(0,100)]          \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,len(hppre.parameter_dictionary['spi'])):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Efracclus = []\n",
    "    for numind in numinds:\n",
    "        reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,number_of_samples,numind)\n",
    "        pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                       1.0/hppre.parameter_dictionary['k'][i],size=number_of_samples)\n",
    "        Efracclus.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))/float(number_of_samples))   \n",
    "    plt.plot(np.asarray(numinds)/float(Npclusi),float(Npclusi)*np.asarray(Efracclus),'g',alpha=0.4)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.axvline(0.01,linestyle='--',color='k')\n",
    "axes.axvline(0.02,linestyle='--',color='k')\n",
    "axes.axhline(1.0,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'$N_{\\rm p}{\\rm E}(f_{\\rm max}^{>1})$')\n",
    "axes.set_xlabel(r'${\\sf p}$')\n",
    "axes.set_ylim([0.0,11.0])\n",
    "axes.set_xlim([0.0,0.03])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond_1000.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhpmig.run_full_stoch(         \\n                    runtime,          \\n                    realisations,  \\n                    do_nothing_timescale,\\n                    'mig' + str(hpmig.parameter_dictionary['Nm'][0]) + '_' + output_filename,  \\n                    timesteps_snapshot=output_timesteps\\n                    )\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpmig = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "              ) \n",
    "\n",
    "hpmig.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hpmig.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hpmig.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hpmig.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hpmig.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hpmig.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hpmig.parameter_dictionary['Np'] = [350,350]       # Number of people within grouping   \n",
    "hpmig.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hpmig.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hpmig.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping\n",
    "\n",
    "hpmig.parameter_dictionary['r+'] = [[0.0,0.0],[52.0,0.0]]  # Migration matrix - the migration rate in (per year)\n",
    "hpmig.parameter_dictionary['r-'] = [[0.0,52.0],[0.0,0.0]]  # Migration matrix - the migration rate out (per year)\n",
    "hpmig.parameter_dictionary['Nm'] = [2]                     # Number of migrants per event (global parameter)\n",
    "\n",
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time  \n",
    "\n",
    "hpmig.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'mig' + str(hpmig.parameter_dictionary['Nm'][0]) + '_' + output_filename,  \n",
    "                    timesteps_snapshot=output_timesteps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "example_output_data = np.loadtxt(path_to_helmpy + '/data/' + output_filename + '.txt')\n",
    "example_output_data_mig1 = np.loadtxt(path_to_helmpy + '/data/' + 'mig1_' + output_filename + '.txt')\n",
    "example_output_data_mig2 = np.loadtxt(path_to_helmpy + '/data/' + 'mig2_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig2.T[0],example_output_data_mig2.T[2],'--',color='b')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig2.T[0],example_output_data_mig2.T[6],color='b')\n",
    "plt.plot(example_output_data_mig2.T[0],example_output_data_mig2.T[8],color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig1.T[0],example_output_data_mig1.T[2],'--',color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig1.T[0],example_output_data_mig1.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_output_data_mig1.T[0],example_output_data_mig1.T[8],color='b',alpha=0.4)\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[2],'--',color='b',alpha=0.2)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[8],color='b',alpha=0.2)\n",
    "plt.plot(example_output_data.T[0],example_output_data.T[11],color='b',alpha=0.2)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,4.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.savefig(path_to_helmpy + '/plots/mig_comp_fo_stabil.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      "  >>>>      >>>>      >>>>      >>>>      >>>>      >>   \n",
      " >>  >>    >>  >>    >>  >>    >>  >>    >>  >>    >> >> \n",
      ">>    >>>>>>    >>>>>>    >>>>>>    >>>>>>    >>>>>>   >>\n",
      ">>                 >>                                    \n",
      ">>                 >>                                    \n",
      ">>         >>>>    >>      >>>    >>>    >>>>>>   >>   >>\n",
      ">>>>>>>   >>  >>   >>     >> >>  >> >>  >>    >>  >>   >>\n",
      ">>    >>  >>  >>   >>     >>  >>>>  >>  >>    >>  >>   >>\n",
      ">>    >>  >>>>>>   >>     >>   >>   >>  >>>>>>>   >>   >>\n",
      ">>    >>  >>       >>     >>        >>  >>        >>   >>\n",
      ">>    >>  >>   >>  >>     >>        >>  >>        >>   >>\n",
      ">>    >>   >>>>>    >>>>> >>        >>  >>         >>>>>>\n",
      "                                                      >> \n",
      "   >>>>      >>>>      >>>>      >>>>      >>>>      >>  \n",
      "  >>  >>    >>  >>    >>  >>    >>  >>    >>  >>    >>   \n",
      ">>>    >>>>>>    >>>>>>    >>>>>>    >>>>>>    >>>>>>    \n",
      "                                                         \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "               Author: Robert J. Hardwick                \n",
      "              DISTRIBUTED UNDER MIT LICENSE              \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "                                                         \n",
      "Setting initial conditions...\n",
      "                       \n",
      "Total number of individuals: 2900\n",
      "Number of clusters: 2\n",
      "                       \n",
      "Inter-cluster migration has been enabled...\n",
      "                                           \n",
      "Now running full stochastic simulation for 100.0 years...\n",
      "                                                                        \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6fd248c28afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;34m'ues_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_filename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mmf_migrations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;31m# Option to draw migration pulses directly from the mean field moments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mmf_migrations_fixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Set the mean field moments to their values at initial conditions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                     )\n",
      "\u001b[0;32m~/work/helmpy/source/helmpy.py\u001b[0m in \u001b[0;36mrun_full_stoch\u001b[0;34m(self, runtime, realisations, do_nothing_timescale, output_filename, timesteps_snapshot, mf_migrations, mf_migrations_fixed)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;31m# Worm death event rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                 \u001b[0mdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmus_ind_perclus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmu1s_ind_perclus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mws_ind_perclus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Total event rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hpues = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages \n",
    "              ) \n",
    "\n",
    "hpues.parameter_dictionary['mu'] = [0.014,0.014,0.014,0.014,0.014,0.014]  # Human death rate (per year)\n",
    "hpues.parameter_dictionary['mu1'] = [0.5,0.5,0.5,0.5,0.5,0.5]             # Adult worm death rate (per year)\n",
    "hpues.parameter_dictionary['mu2'] = [26.0,26.0,26.0,26.0,26.0,26.0]       # Reservoir (eggs and larvae) death rate \n",
    "hpues.parameter_dictionary['R0'] = [3.5,2.1,3.5,2.1,3.5,2.1]              # Basic reproduction number within grouping\n",
    "hpues.parameter_dictionary['k'] = [0.3,0.5,0.3,0.5,0.3,0.5]               # Inverse-clumping factor within grouping\n",
    "hpues.parameter_dictionary['gam'] = [0.08,0.08,0.08,0.08,0.08,0.08]       # Density dependent fecundity: z = exp(-gam)\n",
    "hpues.parameter_dictionary['Np'] = [100,100,350,350,1000,1000]            # Number of people within grouping   \n",
    "hpues.parameter_dictionary['spi'] = [1,2,1,2,1,2]                         # Spatial index number of grouping\n",
    "\n",
    "hpues.initial_conditions['M'] = [2.9,2.1,2.9,2.1,2.9,2.1]                 # Initial mean total worm burden \n",
    "hpues.initial_conditions['FOI'] = [1.25,1.1,1.25,1.1,1.25,1.1]            # Initial force of infection (per year) \n",
    "\n",
    "# Optional initialisation of the separate worm burdens of individuals in each grouping in a list of lists\n",
    "hpues.initial_conditions['wormlist'] = [np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][0], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][0]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][0]))**(-1.0)),size=100)), \\\n",
    "                                        [0.0 for i in range(0,100)],\n",
    "                                        np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][2], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][2]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][2]))**(-1.0)),size=350)), \\\n",
    "                                        [0.0 for i in range(0,350)],\n",
    "                                        np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][4], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][4]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][4]))**(-1.0)),size=1000)), \\\n",
    "                                        [0.0 for i in range(0,1000)]]      \n",
    "\n",
    "# Optional initialisation of the separate uptake rates of individuals in each grouping in a list of lists \n",
    "hpues.initial_conditions['lamlist'] = [np.sort(np.random.gamma(hpues.parameter_dictionary['k'][0], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][0],size=100)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][1], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][1],size=100)),\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][2], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][2],size=350)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][3], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][3],size=350)),\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][4], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][4],size=1000)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][5], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][5],size=1000))]    \n",
    "\n",
    "# Compute the migration rate in units of mu2\n",
    "frac = 0.25\n",
    "mu2 = hpues.parameter_dictionary['mu2'][1]\n",
    "hpues.parameter_dictionary['r+'] = [[0.0,0.0],[mu2*frac,0.0]] # Migration matrix - the migration rate in (per year)\n",
    "hpues.parameter_dictionary['r-'] = [[0.0,mu2*frac],[0.0,0.0]] # Migration matrix - the migration rate out (per year)\n",
    "\n",
    "# Change number of migrants to change migration rate in mu2 units\n",
    "hpues.parameter_dictionary['Nm'] = [1]                        # Number of migrants per event (global parameter) \n",
    "\n",
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "hpues.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'ues_' + output_filename + '_' + str(frac),\n",
    "                    mf_migrations=True,       # Option to draw migration pulses directly from the mean field moments\n",
    "                    mf_migrations_fixed=True  # Set the mean field moments to their values at initial conditions\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/Users/Rob/work/helmpy/data/ues_default_example_0.25_final_prevalences_cluster_2.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b9e3586af0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m example_final_prev1 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.25' + \\\n\u001b[0;32m----> 4\u001b[0;31m                                                   '_final_prevalences_cluster_2.txt')\n\u001b[0m\u001b[1;32m      5\u001b[0m example_final_prev2 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.5' + \\\n\u001b[1;32m      6\u001b[0m                                                   '_final_prevalences_cluster_2.txt')\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /Users/Rob/work/helmpy/data/ues_default_example_0.25_final_prevalences_cluster_2.txt not found."
     ]
    }
   ],
   "source": [
    "output_filename = 'main_text_plot' \n",
    "\n",
    "example_final_prev1 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.25' + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "example_final_prev2 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.5' + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "example_final_prev3 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_1.0' + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "example_final_prev4 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_2.0' + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "example_final_prev5 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_3.0' + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "example_final_prev6 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_4.0' + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "[lq1,uq1] = np.quantile(example_final_prev1,[0.32,0.68])\n",
    "m1 = np.sum(example_final_prev1)/float(len(example_final_prev1))\n",
    "[lq2,uq2] = np.quantile(example_final_prev2,[0.32,0.68])\n",
    "m2 = np.sum(example_final_prev2)/float(len(example_final_prev2))\n",
    "[lq3,uq3] = np.quantile(example_final_prev3,[0.32,0.68])\n",
    "m3 = np.sum(example_final_prev3)/float(len(example_final_prev3))\n",
    "[lq4,uq4] = np.quantile(example_final_prev4,[0.32,0.68])\n",
    "m4 = np.sum(example_final_prev4)/float(len(example_final_prev4))\n",
    "[lq5,uq5] = np.quantile(example_final_prev5,[0.32,0.68])\n",
    "m5 = np.sum(example_final_prev5)/float(len(example_final_prev5))\n",
    "[lq6,uq6] = np.quantile(example_final_prev6,[0.32,0.68])\n",
    "m6 = np.sum(example_final_prev6)/float(len(example_final_prev6))\n",
    "\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,lq1,lq2,lq3,lq4,lq5,lq6],color='r')\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,m1,m2,m3,m4,m5,m6],'--',color='r')\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,uq1,uq2,uq3,uq4,uq5,uq6],color='r')\n",
    "\n",
    "axes=plt.gca()\n",
    "#axes.axhline(0.01,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'${\\sf p}$')\n",
    "axes.set_xlabel(r'$r_+/\\mu_2$')\n",
    "axes.set_xlim([0.0,4.0])\n",
    "axes.set_ylim([0.0,0.08])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_C1C2_uesmigration_100.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'main_text_plot' \n",
    "\n",
    "example_final_prev1 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.25' + \\\n",
    "                                                  '_final_prevalences_cluster_4.txt')\n",
    "example_final_prev2 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.5' + \\\n",
    "                                                  '_final_prevalences_cluster_4.txt')\n",
    "example_final_prev3 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_1.0' + \\\n",
    "                                                  '_final_prevalences_cluster_4.txt')\n",
    "example_final_prev4 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_2.0' + \\\n",
    "                                                  '_final_prevalences_cluster_4.txt')\n",
    "example_final_prev5 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_3.0' + \\\n",
    "                                                  '_final_prevalences_cluster_4.txt')\n",
    "example_final_prev6 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_4.0' + \\\n",
    "                                                  '_final_prevalences_cluster_4.txt')\n",
    "\n",
    "[lq1,uq1] = np.quantile(example_final_prev1,[0.32,0.68])\n",
    "m1 = np.sum(example_final_prev1)/float(len(example_final_prev1))\n",
    "[lq2,uq2] = np.quantile(example_final_prev2,[0.32,0.68])\n",
    "m2 = np.sum(example_final_prev2)/float(len(example_final_prev2))\n",
    "[lq3,uq3] = np.quantile(example_final_prev3,[0.32,0.68])\n",
    "m3 = np.sum(example_final_prev3)/float(len(example_final_prev3))\n",
    "[lq4,uq4] = np.quantile(example_final_prev4,[0.32,0.68])\n",
    "m4 = np.sum(example_final_prev4)/float(len(example_final_prev4))\n",
    "[lq5,uq5] = np.quantile(example_final_prev5,[0.32,0.68])\n",
    "m5 = np.sum(example_final_prev5)/float(len(example_final_prev5))\n",
    "[lq6,uq6] = np.quantile(example_final_prev6,[0.32,0.68])\n",
    "m6 = np.sum(example_final_prev6)/float(len(example_final_prev6))\n",
    "\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,lq1,lq2,lq3,lq4,lq5,lq6],color='b')\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,m1,m2,m3,m4,m5,m6],'--',color='b')\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,uq1,uq2,uq3,uq4,uq5,uq6],color='b')\n",
    "\n",
    "\n",
    "axes=plt.gca()\n",
    "#axes.axhline(0.01,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'${\\sf p}$')\n",
    "axes.set_xlabel(r'$r_+/\\mu_2$')\n",
    "axes.set_xlim([0.0,4.0])\n",
    "axes.set_ylim([0.0,0.08])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_C1C2_uesmigration_350.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'main_text_plot' \n",
    "\n",
    "example_final_prev1 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.25' + \\\n",
    "                                                  '_final_prevalences_cluster_6.txt')\n",
    "example_final_prev2 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_0.5' + \\\n",
    "                                                  '_final_prevalences_cluster_6.txt')\n",
    "example_final_prev3 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_1.0' + \\\n",
    "                                                  '_final_prevalences_cluster_6.txt')\n",
    "example_final_prev4 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_2.0' + \\\n",
    "                                                  '_final_prevalences_cluster_6.txt')\n",
    "example_final_prev5 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_3.0' + \\\n",
    "                                                  '_final_prevalences_cluster_6.txt')\n",
    "example_final_prev6 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '_4.0' + \\\n",
    "                                                  '_final_prevalences_cluster_6.txt')\n",
    "\n",
    "[lq1,uq1] = np.quantile(example_final_prev1,[0.32,0.68])\n",
    "m1 = np.sum(example_final_prev1)/float(len(example_final_prev1))\n",
    "[lq2,uq2] = np.quantile(example_final_prev2,[0.32,0.68])\n",
    "m2 = np.sum(example_final_prev2)/float(len(example_final_prev2))\n",
    "[lq3,uq3] = np.quantile(example_final_prev3,[0.32,0.68])\n",
    "m3 = np.sum(example_final_prev3)/float(len(example_final_prev3))\n",
    "[lq4,uq4] = np.quantile(example_final_prev4,[0.32,0.68])\n",
    "m4 = np.sum(example_final_prev4)/float(len(example_final_prev4))\n",
    "[lq5,uq5] = np.quantile(example_final_prev5,[0.32,0.68])\n",
    "m5 = np.sum(example_final_prev5)/float(len(example_final_prev5))\n",
    "[lq6,uq6] = np.quantile(example_final_prev6,[0.32,0.68])\n",
    "m6 = np.sum(example_final_prev6)/float(len(example_final_prev6))\n",
    "\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,lq1,lq2,lq3,lq4,lq5,lq6],color='g')\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,m1,m2,m3,m4,m5,m6],'--',color='g')\n",
    "plt.plot([0.0,0.25,0.5,1.0,2.0,3.0,4.0],[0.0,uq1,uq2,uq3,uq4,uq5,uq6],color='g')\n",
    "\n",
    "axes=plt.gca()\n",
    "#axes.axhline(0.01,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'${\\sf p}$')\n",
    "axes.set_xlabel(r'$r_+/\\mu_2$')\n",
    "axes.set_xlim([0.0,4.0])\n",
    "axes.set_ylim([0.0,0.08])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_C1C2_uesmigration_1000.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpues = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages \n",
    "              ) \n",
    "\n",
    "hpues.parameter_dictionary['mu'] = [0.014,0.014,0.014,0.014,0.014,0.014]  # Human death rate (per year)\n",
    "hpues.parameter_dictionary['mu1'] = [0.5,0.5,0.5,0.5,0.5,0.5]             # Adult worm death rate (per year)\n",
    "hpues.parameter_dictionary['mu2'] = [26.0,26.0,26.0,26.0,26.0,26.0]       # Reservoir (eggs and larvae) death rate \n",
    "hpues.parameter_dictionary['R0'] = [3.5,2.1,3.5,2.1,3.5,2.1]              # Basic reproduction number within grouping\n",
    "hpues.parameter_dictionary['k'] = [0.3,0.5,0.3,0.5,0.3,0.5]               # Inverse-clumping factor within grouping\n",
    "hpues.parameter_dictionary['gam'] = [0.08,0.08,0.08,0.08,0.08,0.08]       # Density dependent fecundity: z = exp(-gam)\n",
    "hpues.parameter_dictionary['Np'] = [100,100,350,350,1000,1000]            # Number of people within grouping   \n",
    "hpues.parameter_dictionary['spi'] = [1,2,1,2,1,2]                         # Spatial index number of grouping\n",
    "\n",
    "hpues.initial_conditions['M'] = [2.9,2.1,2.9,2.1,2.9,2.1]                 # Initial mean total worm burden \n",
    "hpues.initial_conditions['FOI'] = [1.25,1.1,1.25,1.1,1.25,1.1]            # Initial force of infection (per year) \n",
    "\n",
    "# Optional initialisation of the separate worm burdens of individuals in each grouping in a list of lists\n",
    "hpues.initial_conditions['wormlist'] = [np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][0], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][0]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][0]))**(-1.0)),size=100)), \\\n",
    "                                        [0.0 for i in range(0,100)],\n",
    "                                        np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][2], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][2]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][2]))**(-1.0)),size=350)), \\\n",
    "                                        [0.0 for i in range(0,350)],\n",
    "                                        np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][4], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][4]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][4]))**(-1.0)),size=1000)), \\\n",
    "                                        [0.0 for i in range(0,1000)]]      \n",
    "\n",
    "# Optional initialisation of the separate uptake rates of individuals in each grouping in a list of lists \n",
    "hpues.initial_conditions['lamlist'] = [np.sort(np.random.gamma(hpues.parameter_dictionary['k'][0], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][0],size=100)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][1], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][1],size=100)),\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][2], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][2],size=350)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][3], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][3],size=350)),\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][4], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][4],size=1000)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][5], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][5],size=1000))]    \n",
    "\n",
    "# Compute the migration rate in units of mu2\n",
    "frac = 0.25\n",
    "mu2 = hpues.parameter_dictionary['mu2'][1]\n",
    "hpues.parameter_dictionary['r+'] = [[0.0,0.0],[mu2*frac,0.0]] # Migration matrix - the migration rate in (per year)\n",
    "hpues.parameter_dictionary['r-'] = [[0.0,mu2*frac],[0.0,0.0]] # Migration matrix - the migration rate out (per year)\n",
    "\n",
    "# Change number of migrants to change migration rate in mu2 units\n",
    "hpues.parameter_dictionary['Nm'] = [1]                        # Number of migrants per event (global parameter) \n",
    "\n",
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "hpues.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'ues_' + output_filename + '_' + str(frac) + '_C1C1_' ,\n",
    "                    mf_migrations=True,       # Option to draw migration pulses directly from the mean field moments\n",
    "                    mf_migrations_fixed=True  # Set the mean field moments to their values at initial conditions\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STH plot 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Boolean to see the effect of migration for simplicity...\n",
    "with_migration = False\n",
    "\n",
    "hptrt = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "              ) \n",
    "\n",
    "hptrt.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hptrt.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hptrt.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hptrt.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hptrt.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hptrt.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hptrt.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hptrt.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hptrt.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hptrt.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping\n",
    "\n",
    "if with_migration == True:\n",
    "    hptrt.parameter_dictionary['r+'] = [[0.0,0.0],[52.0,0.0]] # Migration matrix - the migration rate in (per year)\n",
    "    hptrt.parameter_dictionary['r-'] = [[0.0,52.0],[0.0,0.0]] # Migration matrix - the migration rate out (per year)\n",
    "    hptrt.parameter_dictionary['Nm'] = [10]                   # Number of migrants per event (global parameter) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having initialised a new instance, let us define 3 rounds of MDA with 60% coverage at years 15, 16 and 17 to see the effect this has on the disease..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_coverages = [[0.6,0.6,0.6],         # A list of lists matching the chosen groupings which gives \n",
    "                       [0.6,0.6,0.6]]         # the effective coverage fraction in each\n",
    "\n",
    "treatment_times = [15.0,16.0,17.0]            # A list of treatment times for all clusters\n",
    "\n",
    "hptrt.add_treatment_prog(\n",
    "                        treatment_times,         \n",
    "                        treatment_coverages=treatment_coverages,\n",
    "                        drug_efficacy=1.0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the simulation which will output both the mean worm burden dynamics (as before) and the final prevalence realisations at the last round of treatment and at the absolute end of the runs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time\n",
    "\n",
    "if with_migration == False:   \n",
    "    hptrt.run_full_stoch(         \n",
    "                        runtime,          \n",
    "                        realisations,  \n",
    "                        do_nothing_timescale,\n",
    "                        'trt_' + output_filename,  \n",
    "                        timesteps_snapshot=output_timesteps\n",
    "                        )\n",
    "    \n",
    "if with_migration == True:   \n",
    "    hptrt.run_full_stoch(         \n",
    "                        runtime,          \n",
    "                        realisations,  \n",
    "                        do_nothing_timescale,\n",
    "                        'mig_trt_' + output_filename,  \n",
    "                        timesteps_snapshot=output_timesteps\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data_mig_trt = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + '.txt')\n",
    "example_output_data_trt = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hptrt.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hptrt.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hptrt.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hptrt.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hptrt.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hptrt.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hptrt.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hptrt.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hptrt.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hptrt.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[5],color='r')\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with migration\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[6],color='b')\n",
    "plt.plot(example_output_data_mig_trt.T[0],example_output_data_mig_trt.T[8],color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 1 \n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[1],color='r',alpha=0.4)\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[2],color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[5],color='r',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[7],color='r',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[8],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,8.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12, loc = 9)\n",
    "#plt.text(50.0,1.0,r'$(r_+,r_-)=(' + str(hptrt.parameter_dictionary['r+'][0][1]) + ',' + \\\n",
    "#                                    str(hptrt.parameter_dictionary['r-'][0][1]) + ')$',color='r',fontsize=15)\n",
    "plt.savefig(path_to_helmpy + '/plots/treat_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b3)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'mig_trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b4)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Adding individual non-compliance to the treatment rounds\n",
    "\n",
    "The `helmpy` class also contains models for systematic individual non-compliance to the MDA programme in the form of the conditional probabilities of: individuals in the $j$-th grouping being treated in the $n$-th round given treatment in the $(n-1)$-th round $\\alpha^j_{n,n-1}$ and being treated in the $n$-th round given non-treatment in the $(n-1)$-th round $\\beta^j_{n,n-1}$ in a Markov model such that the probability of an individual in the $j$-th grouping is treated in the $n$-th round may be written as\n",
    "\n",
    "$$p_{j,n} = \\alpha^j_{n,n-1} p_{j,n-1} + \\beta^j_{n,n-1} [1 - p_{j,n-1}]\\,.$$\n",
    "\n",
    "To demonstrate how this model impacts the MDA scenario we have already been working with, let us once again re-initialise `helmpy`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpcom = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages\n",
    "              ) \n",
    "\n",
    "hpcom.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hpcom.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hpcom.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hpcom.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hpcom.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hpcom.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hpcom.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hpcom.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hpcom.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hpcom.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having initialised another new instance, let us define the same 3 rounds of MDA with the same effective 60% coverage at years 15, 16 and 17 but with compliance parameters which indicate systematic individual non-compliance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_alpha_betas = [[0.6,0.4,0.97,0.05,0.97,0.05],     # A list of lists matching the chosen groupings which gives \n",
    "                    [0.6,0.4,0.97,0.05,0.97,0.05]]     # the alpha and beta parameters in the order of \n",
    "                                                       # alpha_1, beta_1, alpha_2,... in each, where the \n",
    "                                                       # first round alpha is an initial coverage fraction\n",
    "    \n",
    "treatment_times = [15.0,16.0,17.0]                     # A list of treatment times for all clusters\n",
    "\n",
    "hpcom.add_treatment_prog(\n",
    "                        treatment_times,         \n",
    "                        compliance_params=comp_alpha_betas,\n",
    "                        drug_efficacy=1.0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to run the code and plot the same outputs at the end of the runs as before for comparison..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "output_timesteps = [1000,2000,3000,9000]      # Optional - output binned worm burdens over whole population \n",
    "                                              # and realisations after a specified number of steps in time\n",
    "\n",
    "hpcom.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'com_' + output_filename,  \n",
    "                    timesteps_snapshot=output_timesteps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data_com = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + '.txt')\n",
    "example_output_data_trt = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[1],color='r',\\\n",
    "         label=r'$R_0 =' + str(hpcom.parameter_dictionary['R0'][0]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hpcom.parameter_dictionary['k'][0]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hpcom.parameter_dictionary['Np'][0]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hpcom.initial_conditions['M'][0]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hpcom.initial_conditions['FOI'][0]) + r'$')\n",
    "\n",
    "# Mean of ensemble in cluster 2 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[2],color='b',\\\n",
    "         label=r'$R_0 =' + str(hpcom.parameter_dictionary['R0'][1]) + r'\\,\\,' + \\\n",
    "               r'k =' + str(hpcom.parameter_dictionary['k'][1]) + r'\\,\\,' + \\\n",
    "               r'N_{\\mathrm{p}} =' + str(hpcom.parameter_dictionary['Np'][1]) + r'\\,\\,' + \\\n",
    "               r'M(t_0) =' + str(hpcom.initial_conditions['M'][1]) + r'\\,\\,' + \\\n",
    "               r'\\Lambda (t_0) =' + str(hpcom.initial_conditions['FOI'][1]) + r'$')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[5],color='r')\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 with non-compliance\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[6],color='b')\n",
    "plt.plot(example_output_data_com.T[0],example_output_data_com.T[8],color='b')\n",
    "\n",
    "# Mean of ensemble in cluster 1 \n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[1],color='r',alpha=0.4)\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[2],color='b',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[5],color='r',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[7],color='r',alpha=0.4)\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[6],color='b',alpha=0.4)\n",
    "plt.plot(example_output_data_trt.T[0],example_output_data_trt.T[8],color='b',alpha=0.4)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0,8.5])\n",
    "axes.set_ylabel(r'$m(t)$')\n",
    "axes.set_xlabel(r'$t-t_0$')\n",
    "\n",
    "plt.legend(fontsize = 12, loc = 9)\n",
    "#plt.text(50.0,1.0,r'$(r_+,r_-)=(' + str(hptrt.parameter_dictionary['r+'][0][1]) + ',' + \\\n",
    "#                                    str(hptrt.parameter_dictionary['r-'][0][1]) + ')$',color='r',fontsize=15)\n",
    "plt.savefig(path_to_helmpy + '/plots/noncomptreat_comp.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'trt_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b3)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_lasttreat_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_1.txt')\n",
    "example_final_prev_data = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_1.txt')\n",
    "\n",
    "example_lasttreat_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_lasttreat_prevalences_cluster_2.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'com_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_lasttreat_prev_data,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data,bins='fd')\n",
    "p3,b3 = np.histogram(example_lasttreat_prev_data2,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r',alpha=0.4)\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='r')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),color='b',alpha=0.4)\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b3)]),p4/max(p4),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Running large numbers of people and clusters\n",
    "\n",
    "In order to run `helmpy` with a large number of people and clusters, it is advised to reduce the number of realisations to 1 as the internal vectorisation which optimises the code cannot handle matrices that are too large. The example below tests the runtime of helmpy with 500 people each in 40 clusters including migration and treatment rounds and emphasises the simplicity of using the `helmpy` class to instanciate a run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                              \n",
    "realisations = 1                              \n",
    "do_nothing_timescale = 0.01                                                 \n",
    "    \n",
    "output_filename = 'tests'                  \n",
    "\n",
    "treatment_coverages = [[0.6,0.6,0.6] for j in range(0,40)]                          \n",
    "treatment_times = [15.0,16.0,17.0]     \n",
    "\n",
    "hptest = helmpy('STH',path_to_helmpy,suppress_terminal_output=True) \n",
    "hptest.parameter_dictionary['Np'] = [500 for j in range(0,40)]         \n",
    "hptest.parameter_dictionary['spi'] = [j for j in range(0,40)]         \n",
    "hptest.parameter_dictionary['r+'] = [[10.0*(i!=j) for i in range(0,40)] for j in range(0,40)] \n",
    "hptest.parameter_dictionary['r-'] = [[10.0*(i!=j) for i in range(0,40)] for j in range(0,40)]\n",
    "hptest.add_treatment_prog(treatment_times,treatment_coverages=treatment_coverages,drug_efficacy=1.0) \n",
    "\n",
    "start_time = time.time()\n",
    "hptest.run_full_stoch(runtime,realisations,do_nothing_timescale,output_filename)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Runtime: ' + str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which appears to be around the 22 minute mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Predicting UES migration-induced outbreaks\n",
    "\n",
    "When enough infected humans migrate into a cluster which has achieved elimination, it is possible for them to act as the untreated external source (UES) of a new infection outbreak. This depends not only on the migration rate of people into the area but also on the intensity of infection in the untreated cluster as well as the predisposition to infection of individuals in the previously eliminated cluster. By initialising individuals with worm burdens and pickup rates explicitly in `helmpy`, we may examine the required migration rate for this effect to be significant..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpues = helmpy(\n",
    "              'STH',                              # Set the disease type - types available are: 'STH', 'SCH' and 'LF'\n",
    "              path_to_helmpy,                     # Set the path to the working directory\n",
    "              suppress_terminal_output=False      # Set this to 'True' to remove terminal messages \n",
    "              ) \n",
    "\n",
    "hpues.parameter_dictionary['mu'] = [0.014,0.014]   # Human death rate (per year)\n",
    "hpues.parameter_dictionary['mu1'] = [0.5,0.5]      # Adult worm death rate (per year)\n",
    "hpues.parameter_dictionary['mu2'] = [26.0,26.0]    # Reservoir (eggs and larvae) death rate (per year)\n",
    "hpues.parameter_dictionary['R0'] = [3.5,2.1]       # Basic reproduction number within grouping\n",
    "hpues.parameter_dictionary['k'] = [0.3,0.5]        # Inverse-clumping factor within grouping\n",
    "hpues.parameter_dictionary['gam'] = [0.08,0.08]    # Density dependent fecundity: z = exp(-gam)\n",
    "hpues.parameter_dictionary['Np'] = [300,350]       # Number of people within grouping   \n",
    "hpues.parameter_dictionary['spi'] = [1,2]          # Spatial index number of grouping\n",
    "\n",
    "hpues.initial_conditions['M'] = [2.9,2.1]          # Initial mean total worm burden within grouping\n",
    "hpues.initial_conditions['FOI'] = [1.25,1.1]       # Initial force of infection (per year) within grouping\n",
    "\n",
    "# Optional initialisation of the separate worm burdens of individuals in each grouping in a list of lists\n",
    "hpues.initial_conditions['wormlist'] = [np.sort(np.random.negative_binomial(hpues.parameter_dictionary['k'][0], \\\n",
    "                                        ((1.0+(hpues.initial_conditions['M'][0]/ \\\n",
    "                                        hpues.parameter_dictionary['k'][0]))**(-1.0)),size=300)), \\\n",
    "                                        [0.0 for i in range(0,350)]]      \n",
    "\n",
    "# Optional initialisation of the separate uptake rates of individuals in each grouping in a list of lists \n",
    "hpues.initial_conditions['lamlist'] = [np.sort(np.random.gamma(hpues.parameter_dictionary['k'][0], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][0],size=300)), \\\n",
    "                                       np.sort(np.random.gamma(hpues.parameter_dictionary['k'][1], \\\n",
    "                                       1.0/hpues.parameter_dictionary['k'][1],size=350))]    \n",
    "\n",
    "# Compute the migration rate in units of mu2\n",
    "frac = 1.0\n",
    "mu2 = hpues.parameter_dictionary['mu2'][1]\n",
    "hpues.parameter_dictionary['r+'] = [[0.0,0.0],[mu2*frac,0.0]] # Migration matrix - the migration rate in (per year)\n",
    "hpues.parameter_dictionary['r-'] = [[0.0,mu2*frac],[0.0,0.0]] # Migration matrix - the migration rate out (per year)\n",
    "\n",
    "# Change number of migrants to change migration rate in mu2 units\n",
    "hpues.parameter_dictionary['Nm'] = [1]                        # Number of migrants per event (global parameter) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, it is worth noting that by theoretical arguments, a prevalence threshold of $\\sim 1\\%$ is the elmination breakpoint for a typical realisation of the ensemble. By way of visual representation, we have plot the expected fraction of individuals (using the egg pulse sampler feature of `helmpy`) who will gain more than one worm given that effectively only one individual is contributing to the reservoir at each timestep for a random collection of configurations for the system..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 10**5\n",
    "numinds = [i for i in range(1,10)]\n",
    "\n",
    "hppre = helmpy('STH',path_to_helmpy,suppress_terminal_output=False) \n",
    "hppre.parameter_dictionary['R0'] = [np.random.uniform(2.0,4.0) for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['k'] = [10.0**(-np.random.uniform(0.0,4.0)) for i in range(0,100)]            \n",
    "hppre.parameter_dictionary['Np'] = [300 for i in range(0,100)]       \n",
    "hppre.parameter_dictionary['spi'] = [i for i in range(0,100)]          \n",
    "hppre.initial_conditions['M'] = [np.random.uniform(2.0,5.0) for i in range(0,100)]          \n",
    "\n",
    "# Loop over numbers of individuals contributing to the reservoir\n",
    "for i in range(0,len(hppre.parameter_dictionary['spi'])):\n",
    "    R0clusi = hppre.parameter_dictionary['R0'][i]\n",
    "    Npclusi = hppre.parameter_dictionary['Np'][i]\n",
    "    Efracclus = []\n",
    "    for numind in numinds:\n",
    "        reseggsclusi = hppre.egg_STH_pulse_sampler(hppre.initial_conditions['M'][i],i,number_of_samples,numind)\n",
    "        pickupsclusi = np.random.gamma(hppre.parameter_dictionary['k'][i], \\\n",
    "                                       1.0/hppre.parameter_dictionary['k'][i],size=number_of_samples)\n",
    "        Efracclus.append(np.sum((R0clusi*pickupsclusi*reseggsclusi > Npclusi))/float(number_of_samples))   \n",
    "    plt.plot(np.asarray(numinds)/float(Npclusi),float(Npclusi)*np.asarray(Efracclus),alpha=0.4)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.axvline(0.01,linestyle='--',color='k')\n",
    "axes.axvline(0.02,linestyle='--',color='k')\n",
    "axes.axhline(1.0,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'$N_{\\rm p}{\\rm E}(f_{\\rm max}^{>1})$')\n",
    "axes.set_xlabel(r'${\\sf p}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_cond.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation above demonstrates that if the previously eliminated cluster experiences migration from an UES which exceeds a prevalence of $\\sim 1\\%$ then an outbreak of new infections becomes more likely.\n",
    "\n",
    "Having set the initial conditions in `helmpy` up let us now run some realisations of the full stochastic simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = 100.0                               # Set the total time of the run in years\n",
    "realisations = 250                            # Set the number of stochastic realisations for the model\n",
    "do_nothing_timescale = 0.01                   # Set a timescale (in years) short enough such that an individual \n",
    "                                              # is expected to stay in the same state\n",
    "    \n",
    "output_filename = 'main_text_plot'            # Set a filename for the data to be output in data/\n",
    "            \n",
    "hpues.run_full_stoch(         \n",
    "                    runtime,          \n",
    "                    realisations,  \n",
    "                    do_nothing_timescale,\n",
    "                    'ues_' + output_filename,\n",
    "                    mf_migrations=True,       # Option to draw migration pulses directly from the mean field moments\n",
    "                    mf_migrations_fixed=True  # Set the mean field moments to their values at initial conditions\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a first impression, we shall simply plot the ensemble mean confidence limits of the worm burden in cluster 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_data_ues = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + '.txt')\n",
    "\n",
    "# Mean of ensemble in cluster 1 \n",
    "#plt.plot(example_output_data_ues.T[0],example_output_data_ues.T[1],color='r')\n",
    "\n",
    "# Mean of ensemble in cluster 2\n",
    "plt.plot(example_output_data_ues.T[0],example_output_data_ues.T[2],color='b')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 1 \n",
    "#plt.plot(example_output_data_ues.T[0],example_output_data_ues.T[5],color='r')\n",
    "#plt.plot(example_output_data_ues.T[0],example_output_data_ues.T[7],color='r')\n",
    "\n",
    "# 68% CLs of ensemble in cluster 2 \n",
    "plt.plot(example_output_data_ues.T[0],example_output_data_ues.T[6],color='b')\n",
    "plt.plot(example_output_data_ues.T[0],example_output_data_ues.T[8],color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more detail the distribution over the final prevalences in cluster 2 may be plotted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_final_prev_data1 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "#                                                  '_final_prevalences_cluster_1.txt')\n",
    "example_final_prev_data2 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2.txt')\n",
    "\n",
    "#p1,b1 = np.histogram(example_final_prev_data1,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev_data2,bins='fd')\n",
    "\n",
    "#plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),color='r')\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a number of these simulations have been run for different values of $r_+$, one can plot the final prevalence distributions in cluster 2 to examine the dependency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'main_text_plot' \n",
    "\n",
    "example_final_prev1 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2_r0.25mu.txt')\n",
    "example_final_prev2 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2_r0.5mu.txt')\n",
    "example_final_prev3 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2_r1mu.txt')\n",
    "example_final_prev4 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2_r2mu.txt')\n",
    "example_final_prev5 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2_r3mu.txt')\n",
    "example_final_prev6 = np.loadtxt(path_to_helmpy + '/data/' + 'ues_' + output_filename + \\\n",
    "                                                  '_final_prevalences_cluster_2_r4mu.txt')\n",
    "\n",
    "p1,b1 = np.histogram(example_final_prev1,bins='fd')\n",
    "p2,b2 = np.histogram(example_final_prev2,bins='fd')\n",
    "p3,b3 = np.histogram(example_final_prev3,bins='fd')\n",
    "p4,b4 = np.histogram(example_final_prev4,bins='fd')\n",
    "p5,b5 = np.histogram(example_final_prev5,bins='fd')\n",
    "p6,b6 = np.histogram(example_final_prev6,bins='fd')\n",
    "\n",
    "plt.plot(0.5*(b1[:len(b1)-1]+b1[1:len(b1)]),p1/max(p1),label=r'$r_+=\\mu_2/4$')\n",
    "plt.plot(0.5*(b2[:len(b2)-1]+b2[1:len(b2)]),p2/max(p2),label=r'$r_+=\\mu_2/2$')\n",
    "plt.plot(0.5*(b3[:len(b3)-1]+b3[1:len(b3)]),p3/max(p3),label=r'$r_+=\\mu_2$')\n",
    "plt.plot(0.5*(b4[:len(b4)-1]+b4[1:len(b4)]),p4/max(p4),label=r'$r_+=2\\mu_2$')\n",
    "plt.plot(0.5*(b5[:len(b5)-1]+b5[1:len(b5)]),p5/max(p5),label=r'$r_+=3\\mu_2$')\n",
    "plt.plot(0.5*(b6[:len(b6)-1]+b6[1:len(b6)]),p6/max(p6),label=r'$r_+=4\\mu_2$')\n",
    "plt.legend(fontsize = 12)\n",
    "\n",
    "axes=plt.gca()\n",
    "axes.axvline(0.01,linestyle='--',color='k')\n",
    "axes.set_ylabel(r'${\\rm Pr}({\\sf p},t_{\\rm end})$')\n",
    "axes.set_xlabel(r'${\\sf p}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_to_helmpy + '/plots/prev_uesmigration.png',format='png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
